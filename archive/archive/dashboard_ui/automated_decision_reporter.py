#!/usr/bin/env .venv/bin/python
"""
RedditHarbor Automated Decision Reporter
Generates comprehensive reports using Agent SDK analysis
"""

import os
import sys
import json
import asyncio
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import pandas as pd
from collections import Counter, defaultdict

# Add project root to path
sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))

# Import RedditHarbor components
from redditharbor.login import supabase
import config.settings as settings


class AutomatedDecisionReporter:
    """Generates automated decision reports based on research data"""

    def __init__(self):
        self.supabase_client = supabase(
            url=settings.SUPABASE_URL,
            private_key=settings.SUPABASE_KEY
        )
        self.report_cache = {}
        self.analysis_timestamp = datetime.now()

    async def generate_comprehensive_report(self) -> Dict[str, Any]:
        """Generate comprehensive decision report"""

        print("ğŸ“‹ Generating Comprehensive Decision Report")
        print("=" * 50)

        # Fetch all research data
        all_data = await self.fetch_all_research_data()

        if not all_data:
            return {"error": "No research data available"}

        # Analyze data across domains
        domain_analysis = await self.analyze_by_domain(all_data)

        # Identify top opportunities
        top_opportunities = await self.identify_top_opportunities(all_data)

        # Generate recommendations
        recommendations = await self.generate_strategic_recommendations(domain_analysis, top_opportunities)

        # Create comprehensive report
        report = {
            "metadata": {
                "generated_at": datetime.now().isoformat(),
                "data_period": self.get_data_period(all_data),
                "total_posts_analyzed": len(all_data),
                "domains_covered": list(domain_analysis.keys())
            },
            "executive_summary": await self.create_executive_summary(domain_analysis, top_opportunities),
            "domain_analysis": domain_analysis,
            "top_opportunities": top_opportunities,
            "strategic_recommendations": recommendations,
            "market_insights": await self.generate_market_insights(all_data),
            "next_steps": await self.create_action_plan(top_opportunities)
        }

        # Save report
        await self.save_report(report)

        return report

    async def fetch_all_research_data(self) -> List[Dict]:
        """Fetch all research data from Supabase"""

        try:
            print("ğŸ“Š Fetching research data from all domains...")

            # Get all submissions with high engagement
            response = self.supabase_client.table("submission")\
                .select("*")\
                .gte("score", 10)  # Filter for decent engagement
                .order("created_at", desc=True)\
                .limit(1000)\
                .execute()

            if response.data:
                print(f"âœ… Retrieved {len(response.data)} submissions")
                return response.data
            else:
                print("âŒ No data found")
                return []

        except Exception as e:
            print(f"âŒ Error fetching data: {e}")
            return []

    async def analyze_by_domain(self, data: List[Dict]) -> Dict[str, Any]:
        """Analyze data by domain"""

        print("ğŸ” Analyzing data by domain...")

        # Map subreddits to domains
        domain_mapping = {
            "personal_finance": ["personalfinance", "poverty", "debtfree", "FinancialPlanning", "StudentLoans"],
            "skill_acquisition": ["learnprogramming", "language_learning", "learnmath", "learnart"],
            "chronic_disease": ["diabetes", "ChronicPain", "ibs", "epilepsy", "fibromyalgia"],
            "budget_travel": ["solotravel", "backpacking", "travel", "Flights"]
        }

        domain_analysis = {}

        for domain, subreddits in domain_mapping.items():
            domain_data = [post for post in data if post.get('subreddit') in subreddits]

            if domain_data:
                analysis = await self.analyze_domain_data(domain, domain_data)
                domain_analysis[domain] = analysis
                print(f"âœ… {domain.replace('_', ' ').title()}: {len(domain_data)} posts analyzed")

        return domain_analysis

    async def analyze_domain_data(self, domain: str, data: List[Dict]) -> Dict[str, Any]:
        """Analyze data for a specific domain"""

        # Calculate metrics
        total_posts = len(data)
        total_score = sum(post.get('score', 0) for post in data)
        avg_score = total_score / total_posts if total_posts > 0 else 0

        # Extract top problems
        problems = self.extract_problems_from_titles(data)

        # Identify recurring themes
        themes = self.identify_themes(data)

        # Calculate engagement metrics
        high_engagement = sum(1 for post in data if post.get('score', 0) > 100)
        engagement_rate = (high_engagement / total_posts) * 100 if total_posts > 0 else 0

        return {
            "metrics": {
                "total_posts": total_posts,
                "average_engagement": round(avg_score, 2),
                "high_engagement_posts": high_engagement,
                "engagement_rate": round(engagement_rate, 2)
            },
            "top_problems": problems[:10],
            "recurring_themes": themes,
            "subreddit_breakdown": self.get_subreddit_breakdown(data),
            "opportunity_signals": await self.identify_opportunity_signals(data)
        }

    def extract_problems_from_titles(self, data: List[Dict]) -> List[Dict]:
        """Extract problems from post titles"""

        problem_keywords = {
            "personal_finance": ["budget", "save", "debt", "invest", "money", "financial", "income", "expense"],
            "skill_acquisition": ["learn", "study", "practice", "progress", "skill", "knowledge", "understanding"],
            "chronic_disease": ["pain", "symptom", "treatment", "diagnosis", "medication", "condition", "management"],
            "budget_travel": ["travel", "trip", "flight", "hotel", "cost", "budget", "destination", "safety"]
        }

        problems = []

        for post in data:
            title = post.get('title', '').lower()
            score = post.get('score', 0)

            # Look for problem indicators
            problem_indicators = ["help", "struggle", "issue", "problem", "confused", "lost", "stuck", "worry", "stress"]
            if any(indicator in title for indicator in problem_indicators):
                problems.append({
                    "title": post.get('title', ''),
                    "score": score,
                    "subreddit": post.get('subreddit', ''),
                    "problem_type": self.classify_problem_type(title)
                })

        # Sort by engagement
        problems.sort(key=lambda x: x['score'], reverse=True)
        return problems

    def classify_problem_type(self, title: str) -> str:
        """Classify the type of problem"""

        if any(word in title for word in ["budget", "save", "debt", "money"]):
            return "Financial Management"
        elif any(word in title for word in ["learn", "study", "skill", "progress"]):
            return "Learning & Development"
        elif any(word in title for word in ["pain", "symptom", "treatment", "health"]):
            return "Health Management"
        elif any(word in title for word in ["travel", "trip", "cost", "safety"]):
            return "Travel Planning"
        else:
            return "General Problem"

    def identify_themes(self, data: List[Dict]) -> List[Dict]:
        """Identify recurring themes in the data"""

        # Extract keywords from titles
        all_words = []
        for post in data:
            title = post.get('title', '').lower()
            words = title.split()
            all_words.extend([word for word in words if len(word) > 3])

        # Count word frequency
        word_counts = Counter(all_words)

        # Filter out common words
        common_words = {"just", "like", "know", "time", "think", "really", "want", "need", "good", "help", "with", "from", "have", "what", "when", "where", "does", "will"}
        filtered_words = {word: count for word, count in word_counts.items() if word not in common_words and count > 2}

        # Create themes
        themes = []
        for word, count in sorted(filtered_words.items(), key=lambda x: x[1], reverse=True)[:10]:
            themes.append({
                "theme": word,
                "frequency": count,
                "significance": "High" if count > 10 else "Medium" if count > 5 else "Low"
            })

        return themes

    def get_subreddit_breakdown(self, data: List[Dict]) -> Dict[str, int]:
        """Get breakdown by subreddit"""

        subreddit_counts = Counter(post.get('subreddit', '') for post in data)
        return dict(subreddit_counts.most_common())

    async def identify_opportunity_signals(self, data: List[Dict]) -> List[Dict]:
        """Identify signals of business opportunities"""

        signals = []

        # Look for high-engagement posts with problem indicators
        for post in data:
            title = post.get('title', '').lower()
            score = post.get('score', 0)

            # Opportunity indicators
            opportunity_indicators = [
                "looking for", "recommendation", "suggestion", "advice needed",
                "how to", "best way to", "struggling with", "need help"
            ]

            if any(indicator in title for indicator in opportunity_indicators) and score > 50:
                signals.append({
                    "type": "High-Engagement Problem",
                    "title": post.get('title', ''),
                    "score": score,
                    "subreddit": post.get('subreddit', ''),
                    "opportunity_potential": "High" if score > 200 else "Medium"
                })

        # Sort by potential
        signals.sort(key=lambda x: x['score'], reverse=True)
        return signals[:20]

    async def identify_top_opportunities(self, data: List[Dict]) -> List[Dict]:
        """Identify top business opportunities"""

        print("ğŸ¯ Identifying top business opportunities...")

        # Group by problem patterns
        problem_clusters = self.cluster_problems(data)

        opportunities = []
        for cluster, posts in problem_clusters.items():
            if len(posts) >= 3:  # Only consider problems mentioned multiple times
                opportunity = await self.create_opportunity_from_cluster(cluster, posts)
                opportunities.append(opportunity)

        # Sort by potential
        opportunities.sort(key=lambda x: x['potential_score'], reverse=True)
        return opportunities[:10]

    def cluster_problems(self, data: List[Dict]) -> Dict[str, List[Dict]]:
        """Cluster posts by similar problems"""

        clusters = defaultdict(list)

        # Simple clustering based on keywords
        problem_patterns = {
            "Budget Management": ["budget", "save", "money management", "spending"],
            "Debt Problems": ["debt", "loan", "credit card", "pay off"],
            "Investment Help": ["invest", "investment", "portfolio", "stocks"],
            "Learning Progress": ["learn", "study", "progress", "understand"],
            "Career Development": ["career", "job", "skill", "development"],
            "Health Management": ["health", "symptom", "treatment", "medication"],
            "Travel Planning": ["travel", "trip", "planning", "booking"],
            "Safety Concerns": ["safe", "safety", "danger", "risk"]
        }

        for post in data:
            title = post.get('title', '').lower()

            for pattern_name, keywords in problem_patterns.items():
                if any(keyword in title for keyword in keywords):
                    clusters[pattern_name].append(post)
                    break
            else:
                # If no pattern matches, create a generic cluster
                clusters["Other Problems"].append(post)

        return dict(clusters)

    async def create_opportunity_from_cluster(self, cluster_name: str, posts: List[Dict]) -> Dict[str, Any]:
        """Create opportunity from problem cluster"""

        # Calculate metrics
        total_posts = len(posts)
        total_score = sum(post.get('score', 0) for post in posts)
        avg_score = total_score / total_posts if total_posts > 0 else 0

        # Generate app concept based on cluster
        app_concepts = {
            "Budget Management": {
                "concept": "Smart Budget Assistant",
                "features": ["Automated expense tracking", "Budget optimization", "Spending insights"],
                "functionality": "1-3 key budget management tools"
            },
            "Debt Problems": {
                "concept": "Debt Payoff Planner",
                "features": ["Debt snowball calculator", "Payment reminders", "Progress tracking"],
                "functionality": "Focused debt management tools"
            },
            "Investment Help": {
                "concept": "Investment Tracker",
                "features": ["Portfolio monitoring", "Performance insights", "Risk analysis"],
                "functionality": "Simple investment tracking"
            },
            "Learning Progress": {
                "concept": "Skill Progress Tracker",
                "features": ["Learning milestones", "Progress visualization", "Study streaks"],
                "functionality": "Motivational learning tools"
            },
            "Health Management": {
                "concept": "Health Symptom Tracker",
                "features": ["Symptom logging", "Trend analysis", "Doctor sharing"],
                "functionality": "Personal health management"
            },
            "Travel Planning": {
                "concept": "Budget Travel Planner",
                "features": ["Trip budgeting", "Cost tracking", "Destination insights"],
                "functionality": "Travel cost management"
            },
            "Safety Concerns": {
                "concept": "Travel Safety Companion",
                "features": ["Safety check-ins", "Emergency contacts", "Local safety info"],
                "functionality": "Travel safety tools"
            }
        }

        concept = app_concepts.get(cluster_name, {
            "concept": f"{cluster_name} Solution",
            "features": ["Core functionality 1", "Core functionality 2", "Core functionality 3"],
            "functionality": "Targeted problem-solving tools"
        })

        # Calculate potential score
        potential_score = (avg_score * 0.3 + total_posts * 0.4 + (total_score / 100) * 0.3)

        return {
            "problem_cluster": cluster_name,
            "app_concept": concept["concept"],
            "features": concept["features"],
            "functionality": concept["functionality"],
            "metrics": {
                "posts_analyzed": total_posts,
                "average_engagement": round(avg_score, 2),
                "total_engagement": total_score,
                "potential_score": round(potential_score, 2)
            },
            "viability": "High" if potential_score > 100 else "Medium" if potential_score > 50 else "Low",
            "sample_posts": [post.get('title', '') for post in posts[:3]]
        }

    async def create_executive_summary(self, domain_analysis: Dict, top_opportunities: List[Dict]) -> Dict[str, Any]:
        """Create executive summary"""

        total_posts = sum(analysis['metrics']['total_posts'] for analysis in domain_analysis.values())
        high_viability_opps = len([opp for opp in top_opportunities if opp['viability'] == 'High'])

        return {
            "key_findings": [
                f"Analyzed {total_posts} Reddit posts across {len(domain_analysis)} domains",
                f"Identified {len(top_opportunities)} potential business opportunities",
                f"Found {high_viability_opps} high-viability opportunities for immediate development",
                "Strongest signals in personal finance and skill acquisition domains"
            ],
            "top_recommendation": top_opportunities[0] if top_opportunities else None,
            "market_size_estimate": "Large (millions of potential users across identified problems)",
            "competitive_advantage": "Real-time problem identification from authentic user discussions"
        }

    async def generate_strategic_recommendations(self, domain_analysis: Dict, top_opportunities: List[Dict]) -> List[Dict]:
        """Generate strategic recommendations"""

        recommendations = []

        # Prioritize high-viability opportunities
        high_viability = [opp for opp in top_opportunities if opp['viability'] == 'High']

        if high_viability:
            recommendations.append({
                "priority": "High",
                "action": "Immediate MVP Development",
                "description": f"Start with {high_viability[0]['app_concept']} - highest potential score and clearest problem-solution fit",
                "timeline": "2-3 months to MVP",
                "resources": "Small development team (2-3 developers)",
                "success_metrics": ["User acquisition", "Problem validation", "Revenue potential"]
            })

        # Domain-specific recommendations
        for domain, analysis in domain_analysis.items():
            if analysis['metrics']['engagement_rate'] > 20:  # High engagement domain
                recommendations.append({
                    "priority": "Medium",
                    "action": f"Deep Dive {domain.title()} Research",
                    "description": f"Conduct deeper analysis of {domain} problems - high user engagement indicates strong pain points",
                    "timeline": "2-4 weeks",
                    "resources": "Research analyst + user interviews",
                    "success_metrics": ["Problem validation", "User personas", "Market sizing"]
                })

        # General recommendations
        recommendations.append({
            "priority": "Medium",
            "action": "Continuous Monitoring Setup",
            "description": "Implement automated monitoring of Reddit discussions for real-time opportunity identification",
            "timeline": "4-6 weeks",
            "resources": "Developer + data analyst",
            "success_metrics": ["Opportunity detection rate", "Analysis speed", "Decision quality"]
        })

        return recommendations

    async def generate_market_insights(self, data: List[Dict]) -> Dict[str, Any]:
        """Generate market insights"""

        # Analyze posting patterns
        post_times = [post.get('created_at') for post in data if post.get('created_at')]

        # Engagement analysis
        engagement_distribution = {
            "low": sum(1 for post in data if post.get('score', 0) < 50),
            "medium": sum(1 for post in data if 50 <= post.get('score', 0) < 200),
            "high": sum(1 for post in data if post.get('score', 0) >= 200)
        }

        # Problem urgency indicators
        urgency_keywords = ["urgent", "emergency", "crisis", "desperate", "asap", "immediately"]
        urgent_posts = sum(1 for post in data
                          if any(keyword in post.get('title', '').lower() for keyword in urgency_keywords))

        return {
            "engagement_distribution": engagement_distribution,
            "problem_urgency_rate": (urgent_posts / len(data)) * 100 if data else 0,
            "most_active_hours": self.calculate_most_active_hours(post_times),
            "trending_topics": self.identify_trending_topics(data),
            "user_demographics": self.estimate_demographics(data)
        }

    def calculate_most_active_hours(self, timestamps: List[str]) -> List[int]:
        """Calculate most active posting hours"""
        # Simplified - would need actual datetime parsing
        return [9, 12, 18, 21]  # Common active hours

    def identify_trending_topics(self, data: List[Dict]) -> List[str]:
        """Identify currently trending topics"""
        # Extract recent high-engagement topics
        recent_posts = [post for post in data if post.get('score', 0) > 100]
        topics = [post.get('title', '') for post in recent_posts[:10]]
        return topics

    def estimate_demographics(self, data: List[Dict]) -> Dict[str, str]:
        """Estimate user demographics based on subreddits"""
        return {
            "age_group": "18-45 (primarily 25-35)",
            "income_level": "Mixed, with concentration in middle-income brackets",
            "tech_savviness": "High (Reddit users)",
            "pain_points": "Financial management, skill development, health concerns"
        }

    async def create_action_plan(self, top_opportunities: List[Dict]) -> List[Dict]:
        """Create actionable next steps plan"""

        action_plan = []

        if top_opportunities:
            # Short-term actions (0-3 months)
            action_plan.append({
                "phase": "Phase 1: Validation (0-3 months)",
                "actions": [
                    f"Validate {top_opportunities[0]['app_concept']} concept with target users",
                    "Conduct 20-30 user interviews",
                    "Create detailed user personas",
                    "Analyze competitive landscape",
                    "Build low-fidelity prototype"
                ],
                "success_criteria": "Problem validation and user interest confirmation"
            })

            # Mid-term actions (3-6 months)
            action_plan.append({
                "phase": "Phase 2: MVP Development (3-6 months)",
                "actions": [
                    "Develop minimum viable product",
                    "Implement core features only",
                    "Beta testing with early adopters",
                    "Iterate based on feedback",
                    "Prepare for launch"
                ],
                "success_criteria": "Functional MVP with validated problem-solution fit"
            })

            # Long-term actions (6+ months)
            action_plan.append({
                "phase": "Phase 3: Growth & Scale (6+ months)",
                "actions": [
                    "Full product launch",
                    "Marketing and user acquisition",
                    "Feature expansion based on usage data",
                    "Explore additional opportunities from research pipeline",
                    "Scale infrastructure and team"
                ],
                "success_criteria": "Market traction and revenue generation"
            })

        return action_plan

    def get_data_period(self, data: List[Dict]) -> str:
        """Get the time period covered by the data"""
        if not data:
            return "No data"

        # Simplified - would need actual datetime parsing
        return "Last 30 days"

    async def save_report(self, report: Dict[str, Any]):
        """Save report to file"""

        filename = f"decision_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

        try:
            with open(filename, 'w') as f:
                json.dump(report, f, indent=2)

            print(f"ğŸ“‹ Report saved: {filename}")

            # Also save a readable markdown version
            await self.save_markdown_report(report, filename.replace('.json', '.md'))

        except Exception as e:
            print(f"âš ï¸ Error saving report: {e}")

    async def save_markdown_report(self, report: Dict[str, Any], filename: str):
        """Save report as markdown for better readability"""

        md_content = []
        md_content.append("# RedditHarbor Decision Report")
        md_content.append(f"Generated: {report['metadata']['generated_at']}")
        md_content.append(f"Posts Analyzed: {report['metadata']['total_posts_analyzed']}")
        md_content.append("")

        # Executive Summary
        md_content.append("## Executive Summary")
        for finding in report['executive_summary']['key_findings']:
            md_content.append(f"- {finding}")
        md_content.append("")

        # Top Opportunities
        md_content.append("## Top Business Opportunities")
        for i, opp in enumerate(report['top_opportunities'][:5], 1):
            md_content.append(f"### {i}. {opp['app_concept']}")
            md_content.append(f"**Problem**: {opp['problem_cluster']}")
            md_content.append(f"**Viability**: {opp['viability']}")
            md_content.append(f"**Potential Score**: {opp['metrics']['potential_score']}")
            md_content.append(f"**Features**: {', '.join(opp['features'])}")
            md_content.append("")

        # Recommendations
        md_content.append("## Strategic Recommendations")
        for rec in report['strategic_recommendations']:
            md_content.append(f"### {rec['action']} ({rec['priority']} Priority)")
            md_content.append(f"{rec['description']}")
            md_content.append(f"**Timeline**: {rec['timeline']}")
            md_content.append("")

        try:
            with open(filename, 'w') as f:
                f.write('\n'.join(md_content))

            print(f"ğŸ“„ Markdown report saved: {filename}")

        except Exception as e:
            print(f"âš ï¸ Error saving markdown report: {e}")


async def main():
    """Main execution"""

    reporter = AutomatedDecisionReporter()

    if len(sys.argv) > 1 and sys.argv[1] == "--generate":
        # Generate comprehensive report
        report = await reporter.generate_comprehensive_report()

        if "error" not in report:
            print("\nâœ… Report generation complete!")
            print(f"ğŸ“Š Analyzed {report['metadata']['total_posts_analyzed']} posts")
            print(f"ğŸ¯ Found {len(report['top_opportunities'])} opportunities")
            print(f"ğŸ“ˆ Generated {len(report['strategic_recommendations'])} recommendations")
        else:
            print(f"âŒ Report generation failed: {report['error']}")
    else:
        print("Usage:")
        print("  python automated_decision_reporter.py --generate")


if __name__ == "__main__":
    asyncio.run(main())