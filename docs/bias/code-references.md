# Function-Count Bias: Code References & Exact Locations

**Quick lookup:** Find exact file:line references for all components in the diagnosis.

---

## ğŸ¯ LLM Profiler (Prompt Bias)

### File: `agent_tools/llm_profiler.py`

**Prompt Definition (Lines 70â€“105):**
```
ğŸ“ Line 70:   def _build_prompt(self, text, title, subreddit, score) -> str
ğŸ“ Line 99:   "- 1 function apps get 100 simplicity points (PREFERRED)"
ğŸ“ Line 100:  "- 2 function apps get 85 simplicity points (GOOD)"     â† BIAS HERE
ğŸ“ Line 101:  "- 3 function apps get 70 simplicity points (ACCEPTABLE)"
ğŸ“ Line 102:  "- ALWAYS prefer 1-2 functions over 3 when possible"
```

**Temperature (Deterministic Output):**
```
ğŸ“ Line 124: "temperature": 0.3,  # Lower temp for consistent output
```

**Parse Response (Function Validation):**
```
ğŸ“ Line 149: def _parse_response(self, response: str) -> dict[str, Any]
ğŸ“ Line 179: if not isinstance(profile["core_functions"], list):
ğŸ“ Line 183: if len(profile["core_functions"]) == 0:
ğŸ“ Line 185: elif len(profile["core_functions"]) > 3:
ğŸ“ Line 186:     profile["core_functions"] = profile["core_functions"][:3]
```

**Error Handling (Fallback):**
```
ğŸ“ Line 64: "core_functions": ["Manual analysis needed"],
```

---

## âœ… Constraint Validator (Counting Logic)

### File: `core/dlt/constraint_validator.py`

**DLT Resource Definition:**
```
ğŸ“ Line 14:  @dlt.resource(
ğŸ“ Line 15:  table_name="workflow_results",  â† WRITES TO workflow_results
ğŸ“ Line 16:  write_disposition="merge",
ğŸ“ Line 17:  columns={...}
```

**Schema Definition (Column Types):**
```
ğŸ“ Line 33: "core_functions": {"data_type": "bigint", "nullable": True},  â† INTEGER!
ğŸ“ Line 44: "function_list": {"data_type": "json", "nullable": True},
```

**Main Validation Function:**
```
ğŸ“ Line 42:  def app_opportunities_with_constraint(opportunities: List[Dict])
ğŸ“ Line 56:  for opportunity in opportunities:
ğŸ“ Line 58:  core_functions = _extract_core_functions(opportunity)
ğŸ“ Line 59:  function_count = len(core_functions)
ğŸ“ Line 62:  simplicity_score = _calculate_simplicity_score(function_count)
ğŸ“ Line 65:  opportunity["core_functions"] = function_count  â† CONVERTS TO INTEGER
ğŸ“ Line 67:  opportunity["is_disqualified"] = function_count >= 4
```

**Extract Core Functions (Extraction Priority):**
```
ğŸ“ Line 83:  def _extract_core_functions(opportunity: Dict) -> List[str]
ğŸ“ Line 98:  if "function_list" in opportunity and isinstance(..., list):
ğŸ“ Line 99:    return opportunity["function_list"]  â† PRIMARY PATH
ğŸ“ Line 100: elif "core_functions" in opportunity and isinstance(..., int):
ğŸ“ Line 102:   return [f"function_{i+1}" for i in range(...)]  â† FALLBACK 1
ğŸ“ Line 105: return _parse_functions_from_text(text)  â† FALLBACK 2
```

**Simplicity Scoring:**
```
ğŸ“ Line 109: def _calculate_simplicity_score(function_count: int) -> float
ğŸ“ Line 125: if function_count == 1: return 100.0
ğŸ“ Line 127: elif function_count == 2: return 85.0
ğŸ“ Line 129: elif function_count == 3: return 70.0
ğŸ“ Line 131: else: return 0.0  # AUTOMATIC DISQUALIFICATION
```

**Text Parsing (Regex patterns for extraction):**
```
ğŸ“ Line 135: def _parse_functions_from_text(text: str) -> List[str]
ğŸ“ Line 154: patterns = [...]  â† Multiple regex patterns
ğŸ“ Line 189: return functions[:3]  â† CLIPPED TO 3
```

---

## ğŸ“Š Schema Definitions

### File: `core/dlt/schemas/app_opportunities_schema.py`

**app_opportunities Table (Profiling Data):**
```
ğŸ“ Line 23:  app_opportunities_schema.add_table(
ğŸ“ Line 24:      table_name="app_opportunities",
ğŸ“ Line 43:      {"name": "core_functions", "type": "bigint", "nullable": True},  â† INTEGER!
ğŸ“ Line 53:      {"name": "function_list", "type": "json", "nullable": True},  â† JSON ARRAY
```

**Constraint Violations Table:**
```
ğŸ“ Line 74:  app_opportunities_schema.add_table(
ğŸ“ Line 75:      table_name="constraint_violations",
ğŸ“ Line 80:      {"name": "function_count", "type": "bigint", ...},
```

**Schema Documentation:**
```
ğŸ“ Line 127: SCHEMA_DOCUMENTATION = {...}
ğŸ“ Line 131: "core_functions: Number of core functions (0-10, max allowed is 3)",
```

---

### File: `core/dlt_app_opportunities.py`

**DLT Resource (Separate Definition):**
```
ğŸ“ Line 37:  @dlt.resource(
ğŸ“ Line 38:      name="app_opportunities",
ğŸ“ Line 39:      write_disposition="merge",
ğŸ“ Line 44:      "core_functions": {"data_type": "json", "nullable": False},  â† JSON!
```

**Schema Mismatch Summary:**
```
Validator (constraint_validator.py:33)    â†’ INTEGER
Resource (dlt_app_opportunities.py:44)    â†’ JSON
Database (workflow_results)               â†’ BIGINT
Database (app_opportunities schema)       â†’ BIGINT
Actual table (app_opportunities)          â†’ varies (see migration)
```

---

## ğŸ—„ï¸ Database Migrations

### File: `supabase/migrations/20251108000001_workflow_results_table.sql`

**Table Creation:**
```sql
ğŸ“ Line 4:   CREATE TABLE IF NOT EXISTS workflow_results (
ğŸ“ Line 8:   function_count INTEGER NOT NULL,
ğŸ“ Line 9:   function_list TEXT[] DEFAULT '{}',
```

**Problem:** 
- `function_count` is INTEGER (stores count like 2)
- `function_list` is TEXT[] (stores array, but not used by validator)
- Constraint validator overwrites with `core_functions` BIGINT (line 33 of schema)

---

## ğŸ“¤ Batch Processing Pipeline

### File: `scripts/batch_opportunity_scoring.py`

**Data Preparation:**
```
ğŸ“ Line 308: def prepare_analysis_for_storage(submission_id, analysis, sector)
ğŸ“ Line 330: core_functions = analysis.get("core_functions", [])
ğŸ“ Line 331: if isinstance(core_functions, list):
ğŸ“ Line 332:     function_count = len(core_functions)
ğŸ“ Line 333:     function_list = core_functions
ğŸ“ Line 334: else:
ğŸ“ Line 335:     function_count = core_functions if isinstance(..., int) else 1
ğŸ“ Line 338:     function_list = [f"Core function {i+1}" for i in range(...)]
ğŸ“ Line 341: analysis_data = {
ğŸ“ Line 345:     "function_count": function_count,
ğŸ“ Line 346:     "function_list": function_list,
```

**DLT Loading (Constraint Validation):**
```
ğŸ“ Line 370: def load_scores_to_supabase_via_dlt(scored_opportunities)
ğŸ“ Line 399: validated_opportunities = list(app_opportunities_with_constraint(...))
ğŸ“ Line 424: load_info = pipeline.run(
ğŸ“ Line 425:     app_opportunities_with_constraint(scored_opportunities),
```

**AI Profile Storage (Separate Path):**
```
ğŸ“ Line 451: def store_ai_profiles_to_app_opportunities_via_dlt(scored_opportunities)
ğŸ“ Line 478:     "core_functions": opp.get("function_list", []),  â† ARRAY, NOT COUNT
ğŸ“ Line 493: success = load_app_opportunities(ai_profiles)
```

---

## ğŸ¯ Where Data Diverges (Two Paths)

### Path A: Validation (Constraint Validator)
```
batch_opportunity_scoring.py:399
    â†“
app_opportunities_with_constraint() [constraint_validator.py:42]
    â†“
DLT resource writes to: workflow_results
    â†“
workflow_results.core_functions = 2 (INTEGER count)
```

### Path B: Profiling (AI Profiles)
```
batch_opportunity_scoring.py:451
    â†“
store_ai_profiles_to_app_opportunities_via_dlt()
    â†“
load_app_opportunities() [core/dlt_app_opportunities.py:72]
    â†“
DLT resource writes to: app_opportunities
    â†“
app_opportunities.core_functions = ["Track", "Log"] (JSON array)
```

---

## ğŸ” Opportunity Analyzer (Missing Step)

### File: `agent_tools/opportunity_analyzer_agent.py`

**Main Analysis Function:**
```
ğŸ“ Line 89: def analyze_opportunity(self, submission_data: Dict) -> Dict
ğŸ“ Line 120: scores = {
ğŸ“ Line 121:     "market_demand": market_demand,
ğŸ“ Line 122:     ...
ğŸ“ Line 126:     "simplicity_score": 70.0  # Default: Will be updated by constraint validator
ğŸ“ Line 127: }
ğŸ“ Line 132: result = {
ğŸ“ Line 135:     "dimension_scores": scores,
         â† NO core_functions here!
```

**Finding:** OpportunityAnalyzer does NOT generate functions; only LLMProfiler does.

---

## ğŸ§ª Test Locations

### File: `tests/test_function_count_bias.py`

**Diagnostic Tests:**
```
ğŸ“ Line 19:  def test_function_count_distribution_shows_bias(self)
ğŸ“ Line 38:  def test_all_opportunities_have_function_data(self)
ğŸ“ Line 72:  def test_function_count_consistency_in_workflow_results(self)
```

**Unit Tests:**
```
ğŸ“ Line 104: def test_llm_profiler_respects_constraint(self)
ğŸ“ Line 124: def test_constraint_validator_counts_correctly(self)
```

**Acceptance Tests:**
```
ğŸ“ Line 250: def test_acceptance_function_count_distribution(self)
ğŸ“ Line 280: def test_acceptance_no_nulls(self)
ğŸ“ Line 304: def test_acceptance_all_in_range(self)
```

---

## ğŸ“‹ Summary Table: Code Locations

| Component | File | Lines | Issue |
|-----------|------|-------|-------|
| **LLM Prompt Bias** | agent_tools/llm_profiler.py | 99â€“102 | Prefers 2 (INTENTIONAL) |
| **Temperature** | agent_tools/llm_profiler.py | 124 | 0.3 = deterministic |
| **Validator** | core/dlt/constraint_validator.py | 42â€“80 | Counts correctly, but... |
| **Validator Schema** | core/dlt/constraint_validator.py | 33 | Stores as INTEGER |
| **Analyzer Missing** | agent_tools/opportunity_analyzer_agent.py | 89â€“143 | No functions returned |
| **Data Prep** | scripts/batch_opportunity_scoring.py | 308â€“368 | Correctly extracts |
| **DLT Load (Path A)** | scripts/batch_opportunity_scoring.py | 370â€“449 | workflow_results |
| **AI Profiles (Path B)** | scripts/batch_opportunity_scoring.py | 451â€“494 | app_opportunities |
| **Schema A** | core/dlt/schemas/app_opportunities_schema.py | 43 | INTEGER type |
| **Schema B** | core/dlt_app_opportunities.py | 44 | JSON type |
| **Migration** | supabase/migrations/20251108000001...sql | 4â€“9 | TEXT[] vs INTEGER |

---

## ğŸ”— Reference Navigation

**Questions?**
- "Where does the bias come from?" â†’ agent_tools/llm_profiler.py:99â€“102
- "How is it validated?" â†’ core/dlt/constraint_validator.py:42â€“80
- "Where does it get stored?" â†’ workflow_results + app_opportunities (two tables!)
- "Why are there two paths?" â†’ scripts/batch_opportunity_scoring.py:370 vs 451
- "What's the schema mismatch?" â†’ app_opportunities_schema.py:43 vs dlt_app_opportunities.py:44
- "What's missing?" â†’ Post-profiling validation step

---

**All file references verified as of 2025-11-10**
**No files have been modifiedâ€”all proposals only**

