# RedditHarbor Repository Structure Strategy

**Decision:** Polyrepo (Separate Repositories) with Database as Contract

**Last Updated:** 2025-11-11

---

## TL;DR: The Recommendation

```
Repository Structure: POLYREPO (2 separate repos)

Repo 1: redditharbor (existing Python)
‚îú‚îÄ‚îÄ GitHub: github.com/ai-rio/redditharbor
‚îú‚îÄ‚îÄ Hosts: Python scripts, data collection, scoring
‚îú‚îÄ‚îÄ Deploys: GitHub Actions (cron jobs)
‚îú‚îÄ‚îÄ Writes: To Supabase database

Repo 2: redditharbor-web (new Next.js)
‚îú‚îÄ‚îÄ GitHub: github.com/ai-rio/redditharbor-web
‚îú‚îÄ‚îÄ Hosts: Next.js frontend + API routes
‚îú‚îÄ‚îÄ Deploys: Vercel (continuous deployment)
‚îú‚îÄ‚îÄ Reads: From Supabase database

Contract: Supabase database schema (single source of truth)
```

**Why:** Clean separation, independent deployment, minimal coupling, easier to maintain.

---

## Analysis of All Options

### Option 1: Monorepo (Single Repository)

```
redditharbor/
‚îú‚îÄ‚îÄ .git/
‚îú‚îÄ‚îÄ python/
‚îÇ   ‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ web/
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îî‚îÄ‚îÄ next.config.js
‚îú‚îÄ‚îÄ docs/
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îú‚îÄ‚îÄ python-cron.yml
‚îÇ       ‚îî‚îÄ‚îÄ web-deploy.yml
‚îî‚îÄ‚îÄ README.md
```

**Pros:**
- ‚úÖ Single source of truth
- ‚úÖ Easier to keep documentation in sync
- ‚úÖ Single version control history
- ‚úÖ Share types/schemas easily
- ‚úÖ One `git clone` for everything

**Cons:**
- ‚ùå Larger repo size (slower clones)
- ‚ùå CI/CD more complex (need to detect which part changed)
- ‚ùå Deployment still separate anyway (Vercel vs GitHub Actions)
- ‚ùå Mixed tech stacks in one repo (confusing)
- ‚ùå Python team sees Next.js changes (noise)
- ‚ùå Need monorepo tools (Nx, Turborepo, Lerna)

**When to Use:**
- Services share significant code
- Frequent coordinated changes across both
- Single team managing everything
- Need atomic commits across services

**Verdict for RedditHarbor:** ‚ùå **Not recommended**
- Python and Next.js don't share code
- They communicate via database, not imports
- Independent deployment cycles
- Overkill for your architecture

---

### Option 2: Polyrepo (Separate Repositories) ‚≠ê RECOMMENDED

```
Repository 1: redditharbor (Python)
github.com/ai-rio/redditharbor/
‚îú‚îÄ‚îÄ .git/
‚îú‚îÄ‚îÄ scripts/
‚îú‚îÄ‚îÄ core/
‚îú‚îÄ‚îÄ config/
‚îú‚îÄ‚îÄ docs/
‚îú‚îÄ‚îÄ tests/
‚îú‚îÄ‚îÄ .github/workflows/
‚îî‚îÄ‚îÄ README.md

Repository 2: redditharbor-web (Next.js)
github.com/ai-rio/redditharbor-web/
‚îú‚îÄ‚îÄ .git/
‚îú‚îÄ‚îÄ app/
‚îú‚îÄ‚îÄ components/
‚îú‚îÄ‚îÄ lib/
‚îú‚îÄ‚îÄ public/
‚îú‚îÄ‚îÄ docs/
‚îî‚îÄ‚îÄ README.md

Contract: Supabase database schema
‚îú‚îÄ‚îÄ Defined in Supabase migrations
‚îú‚îÄ‚îÄ Both repos reference same tables
‚îú‚îÄ‚îÄ Schema docs shared via documentation
```

**Pros:**
- ‚úÖ Clean separation of concerns
- ‚úÖ Independent deployment cycles
- ‚úÖ Smaller, focused repositories
- ‚úÖ No need for monorepo tooling
- ‚úÖ Easier to understand (one responsibility per repo)
- ‚úÖ Can have different contributors per repo
- ‚úÖ Vercel auto-deploys web only
- ‚úÖ GitHub Actions only runs Python when Python changes

**Cons:**
- ‚ùå Need to keep database schema in sync manually
- ‚ùå Documentation can diverge
- ‚ùå Two repos to manage (2x git operations)
- ‚ùå Shared types need to be duplicated or generated

**How to Mitigate Cons:**
1. **Schema sync:** Use Supabase as single source of truth
2. **Type generation:** Generate TypeScript types from Supabase
3. **Documentation:** Link between repos in README
4. **Shared changes:** Rare, coordinate via issues/PRs

**When to Use:**
- Services communicate via API/database (‚úÖ Your case)
- Different tech stacks (‚úÖ Python vs TypeScript)
- Independent deployment (‚úÖ GitHub Actions vs Vercel)
- Different update frequencies (‚úÖ Daily cron vs iterative)

**Verdict for RedditHarbor:** ‚úÖ **RECOMMENDED**
- Perfect fit for your architecture
- Simplest to maintain
- Standard industry practice for this pattern

---

### Option 3: Service-Based Repos (Microservices)

```
Repo 1: redditharbor-collector
‚îú‚îÄ‚îÄ Reddit collection scripts
‚îî‚îÄ‚îÄ Deploy: GitHub Actions

Repo 2: redditharbor-scorer
‚îú‚îÄ‚îÄ Opportunity scoring logic
‚îî‚îÄ‚îÄ Deploy: GitHub Actions

Repo 3: redditharbor-api
‚îú‚îÄ‚îÄ Next.js API routes only
‚îî‚îÄ‚îÄ Deploy: Vercel

Repo 4: redditharbor-frontend
‚îú‚îÄ‚îÄ Next.js UI components only
‚îî‚îÄ‚îÄ Deploy: Vercel

Contract: API specifications between services
```

**Pros:**
- ‚úÖ Maximum separation
- ‚úÖ Each service independently scalable
- ‚úÖ Different teams per service

**Cons:**
- ‚ùå Massive overkill for your use case
- ‚ùå 4+ repos to manage
- ‚ùå Complex coordination
- ‚ùå Over-engineering for a solo founder/small team

**When to Use:**
- Large teams (10+ engineers)
- True microservices architecture
- Each service is massive
- Need independent scaling per service

**Verdict for RedditHarbor:** ‚ùå **Overkill**
- You're not Netflix
- Solo founder/small team
- Adds complexity with no benefit

---

### Option 4: Hybrid Monorepo

```
Repo 1: redditharbor (monorepo with workspace)
‚îú‚îÄ‚îÄ packages/
‚îÇ   ‚îú‚îÄ‚îÄ shared/          # Shared types, schemas
‚îÇ   ‚îú‚îÄ‚îÄ python/          # Python scripts
‚îÇ   ‚îî‚îÄ‚îÄ web/             # Next.js
‚îú‚îÄ‚îÄ .github/workflows/
‚îî‚îÄ‚îÄ package.json         # Workspace root
```

**Pros:**
- ‚úÖ Shared code in one place
- ‚úÖ Single repo for everything
- ‚úÖ Can share types via packages/shared

**Cons:**
- ‚ùå Need package manager workspaces (pnpm/yarn/npm)
- ‚ùå Python doesn't use npm (awkward setup)
- ‚ùå Still deploy separately anyway
- ‚ùå More complex than needed

**When to Use:**
- Frontend and backend share significant code
- Using same tech stack across services
- Need to import shared packages

**Verdict for RedditHarbor:** ‚ùå **Unnecessary complexity**
- Python and Node.js don't share code naturally
- Database schema is the contract, not shared packages

---

## Recommended Structure: Polyrepo Details

### Repository 1: redditharbor (Python - EXISTING)

**Location:** `github.com/ai-rio/redditharbor`

**Purpose:** Data collection, scoring, AI profiling

**Structure:**
```
redditharbor/
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îî‚îÄ‚îÄ daily-collection.yml          # Cron jobs
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ settings.py                       # Environment config
‚îÇ   ‚îî‚îÄ‚îÄ dlt_settings.py                   # DLT config
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ collection.py                     # Reddit collection
‚îÇ   ‚îú‚îÄ‚îÄ dlt_reddit_source.py              # DLT source
‚îÇ   ‚îú‚îÄ‚îÄ activity_validation.py            # Activity scoring
‚îÇ   ‚îî‚îÄ‚îÄ supabase_client.py                # Supabase writes
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ automated_opportunity_collector.py
‚îÇ   ‚îú‚îÄ‚îÄ batch_opportunity_scorer.py
‚îÇ   ‚îî‚îÄ‚îÄ real_ai_app_profiler.py
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ business/                         # Your docs
‚îÇ   ‚îú‚îÄ‚îÄ technical/
‚îÇ   ‚îî‚îÄ‚îÄ guides/
‚îú‚îÄ‚îÄ tests/
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

**Deployment:**
- GitHub Actions (cron schedule)
- Runs daily at 9 AM UTC
- Writes to Supabase

**Environment Variables (GitHub Secrets):**
```
SUPABASE_URL
SUPABASE_SERVICE_KEY
REDDIT_CLIENT_ID
REDDIT_CLIENT_SECRET
REDDIT_USER_AGENT
OPENROUTER_API_KEY
```

---

### Repository 2: redditharbor-web (Next.js - NEW)

**Location:** `github.com/ai-rio/redditharbor-web`

**Purpose:** Customer-facing website, dashboard, API routes

**Structure:**
```
redditharbor-web/
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îî‚îÄ‚îÄ vercel-deploy.yml             # Auto-deploy on push
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ page.tsx                          # Landing page
‚îÇ   ‚îú‚îÄ‚îÄ pricing/
‚îÇ   ‚îú‚îÄ‚îÄ dashboard/
‚îÇ   ‚îú‚îÄ‚îÄ opportunities/[id]/
‚îÇ   ‚îú‚îÄ‚îÄ auth/
‚îÇ   ‚îî‚îÄ‚îÄ api/
‚îÇ       ‚îú‚îÄ‚îÄ opportunities/
‚îÇ       ‚îú‚îÄ‚îÄ user/
‚îÇ       ‚îú‚îÄ‚îÄ checkout/
‚îÇ       ‚îî‚îÄ‚îÄ webhooks/
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ ui/                               # Shadcn components
‚îÇ   ‚îú‚îÄ‚îÄ OpportunityCard.tsx
‚îÇ   ‚îú‚îÄ‚îÄ CredibilityBadge.tsx
‚îÇ   ‚îî‚îÄ‚îÄ PricingTable.tsx
‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îú‚îÄ‚îÄ supabase/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ client.ts                     # Client-side
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ server.ts                     # Server-side
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api.ts                        # API routes
‚îÇ   ‚îú‚îÄ‚îÄ stripe.ts
‚îÇ   ‚îî‚îÄ‚îÄ database.types.ts                 # Generated from Supabase
‚îú‚îÄ‚îÄ public/
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îî‚îÄ‚îÄ README.md                         # Link to main repo
‚îú‚îÄ‚îÄ .env.local.example
‚îú‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ next.config.js
‚îú‚îÄ‚îÄ tailwind.config.ts
‚îî‚îÄ‚îÄ README.md
```

**Deployment:**
- Vercel (auto-deploy on push to main)
- Preview deployments on PRs

**Environment Variables (Vercel):**
```
NEXT_PUBLIC_SUPABASE_URL
NEXT_PUBLIC_SUPABASE_ANON_KEY
SUPABASE_SERVICE_ROLE_KEY
NEXT_PUBLIC_STRIPE_PUBLISHABLE_KEY
STRIPE_SECRET_KEY
STRIPE_WEBHOOK_SECRET
NEXT_PUBLIC_APP_URL
```

---

## The Database Contract

**Supabase is the single source of truth:**

```
Contract between Python and Next.js:

Database Schema (Supabase):
‚îú‚îÄ‚îÄ opportunities table
‚îú‚îÄ‚îÄ problem_metrics table
‚îú‚îÄ‚îÄ workflow_results table
‚îú‚îÄ‚îÄ users table (Supabase Auth)
‚îî‚îÄ‚îÄ subscriptions table

Python:  WRITES ‚Üí Supabase
Next.js: READS  ‚Üê Supabase
```

**How to Keep in Sync:**

1. **Use Supabase Migrations as Source of Truth:**
   ```sql
   -- redditharbor/supabase/migrations/xxx_opportunities.sql
   CREATE TABLE opportunities (
     id UUID PRIMARY KEY,
     title TEXT,
     score NUMERIC,
     ...
   );
   ```

2. **Generate Types for Next.js:**
   ```bash
   # In redditharbor-web/
   supabase gen types typescript --linked > lib/database.types.ts
   ```

3. **Python Uses Same Schema:**
   ```python
   # In redditharbor/
   supabase.table('opportunities').insert({
     'title': title,
     'score': score,
     ...
   })
   ```

4. **Documentation Links:**
   ```markdown
   # redditharbor/README.md
   Related repositories:
   - Web frontend: github.com/ai-rio/redditharbor-web

   # redditharbor-web/README.md
   Related repositories:
   - Python backend: github.com/ai-rio/redditharbor
   ```

---

## Deployment Strategy

### Python Repository (redditharbor)

**Hosting:** GitHub Actions (free)

**Workflow:**
```yaml
# .github/workflows/daily-collection.yml
name: Daily Collection
on:
  schedule:
    - cron: '0 9 * * *'  # 9 AM UTC daily
  workflow_dispatch:

jobs:
  collect:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v4
      - run: pip install -r requirements.txt
      - run: python scripts/automated_opportunity_collector.py
      - run: python scripts/batch_opportunity_scorer.py
      - run: python scripts/real_ai_app_profiler.py
```

**When it runs:**
- Automatically at 9 AM UTC daily
- Manually via "Run workflow" button
- Never "deployed" in traditional sense (just scheduled jobs)

---

### Next.js Repository (redditharbor-web)

**Hosting:** Vercel (free tier)

**Deployment:**
- Push to `main` ‚Üí Auto-deploys to production
- Push to other branch ‚Üí Preview deployment
- No workflow needed (Vercel handles it)

**Setup:**
1. Connect GitHub repo to Vercel
2. Configure environment variables
3. Done - auto-deploys forever

---

## Development Workflow

### Working on Python

```bash
# Clone Python repo
git clone github.com/ai-rio/redditharbor
cd redditharbor

# Make changes
vim scripts/automated_opportunity_collector.py

# Test locally
python scripts/automated_opportunity_collector.py

# Commit and push
git add .
git commit -m "feat: improve collection logic"
git push

# GitHub Actions will run on next scheduled time
```

### Working on Next.js

```bash
# Clone Next.js repo
git clone github.com/ai-rio/redditharbor-web
cd redditharbor-web

# Install dependencies
npm install

# Run locally
npm run dev  # http://localhost:3000

# Make changes
vim app/page.tsx

# Commit and push
git add .
git commit -m "feat: add landing page"
git push

# Vercel auto-deploys in 2-3 minutes
```

### Working on Both (Schema Change)

**Example: Adding new column to opportunities table**

```bash
# 1. In redditharbor repo (Python)
cd redditharbor

# Create Supabase migration
supabase migration new add_difficulty_score

# Edit migration
vim supabase/migrations/xxx_add_difficulty_score.sql
# ALTER TABLE opportunities ADD COLUMN difficulty_score NUMERIC;

# Apply migration
supabase db push

# Update Python code
vim scripts/batch_opportunity_scorer.py
# Add difficulty_score to insert

# Commit
git add .
git commit -m "feat: add difficulty scoring"
git push

# 2. In redditharbor-web repo (Next.js)
cd ../redditharbor-web

# Regenerate types
supabase gen types typescript --linked > lib/database.types.ts

# Update Next.js components
vim components/OpportunityCard.tsx
# Add difficulty badge

# Commit
git add .
git commit -m "feat: show difficulty score"
git push

# Both deployed independently
```

---

## Shared Documentation Strategy

### Option A: Keep Docs in Python Repo (Recommended)

```
redditharbor/
‚îî‚îÄ‚îÄ docs/
    ‚îú‚îÄ‚îÄ business/
    ‚îú‚îÄ‚îÄ technical/
    ‚îî‚îÄ‚îÄ guides/

redditharbor-web/
‚îî‚îÄ‚îÄ README.md  # Links to main docs
```

**Pros:**
- Single source of truth for docs
- Business docs naturally live with data logic

**Cons:**
- Next.js contributors need to look elsewhere for docs

### Option B: Duplicate Minimal Docs

```
redditharbor/
‚îî‚îÄ‚îÄ docs/
    ‚îî‚îÄ‚îÄ [All docs]

redditharbor-web/
‚îî‚îÄ‚îÄ docs/
    ‚îî‚îÄ‚îÄ frontend-specific.md
```

**Pros:**
- Each repo self-contained

**Cons:**
- Risk of docs diverging

**Recommendation:** Option A (docs in Python repo, link from Next.js)

---

## Schema Versioning Strategy

**Problem:** How to ensure Python and Next.js use compatible schemas?

**Solution: Database Migrations as Contract**

1. **All schema changes in Supabase migrations:**
   ```
   redditharbor/supabase/migrations/
   ‚îú‚îÄ‚îÄ 001_initial_schema.sql
   ‚îú‚îÄ‚îÄ 002_add_problem_metrics.sql
   ‚îî‚îÄ‚îÄ 003_add_difficulty_score.sql
   ```

2. **Python and Next.js both reference same Supabase:**
   - Python writes to tables
   - Next.js reads from tables
   - Supabase enforces schema

3. **Breaking changes are rare:**
   - Adding columns: Safe (Python adds, Next.js ignores until updated)
   - Renaming columns: Coordinate (but rare)
   - Deleting columns: Coordinate (but rare)

4. **Version in package.json/pyproject.toml (optional):**
   ```json
   // redditharbor-web/package.json
   "version": "1.0.0"

   # redditharbor/pyproject.toml
   version = "1.0.0"
   ```

---

## Cost Analysis

### Monorepo Costs
- **Time:** +2-4 hours setup (monorepo tooling)
- **Maintenance:** +10% ongoing (more complex)
- **Mental Overhead:** High (which part changed?)

### Polyrepo Costs
- **Time:** 0 hours setup (just create 2nd repo)
- **Maintenance:** Standard (each repo simple)
- **Mental Overhead:** Low (clear separation)

### Verdict: Polyrepo is cheaper in every dimension

---

## Migration Plan (From Current State)

**Current:** You have `redditharbor` Python repo

**Goal:** Add `redditharbor-web` Next.js repo

### Step-by-Step

```bash
# 1. Create new Next.js repo on GitHub
# Go to github.com ‚Üí New Repository
# Name: redditharbor-web
# Public/Private: Same as Python repo

# 2. Clone and initialize
git clone github.com/ai-rio/redditharbor-web
cd redditharbor-web

# 3. Create Next.js app
npx create-next-app@latest . --typescript --tailwind --app --no-src-dir

# 4. Follow nextjs-setup-guide.md
# (Install dependencies, create components, etc.)

# 5. Link repos in README
echo "## Related Repositories
- Python backend: github.com/ai-rio/redditharbor
- Database: Supabase (shared)
" >> README.md

# 6. Push
git add .
git commit -m "Initial Next.js setup"
git push

# 7. Connect to Vercel
# Go to vercel.com ‚Üí Import Project ‚Üí Select redditharbor-web

# Done! Two independent repos, one system.
```

---

## Troubleshooting Common Issues

### Issue: Schema out of sync

**Symptom:** Next.js expects column that doesn't exist

**Solution:**
```bash
# 1. Check Supabase schema in dashboard
# 2. Regenerate types in redditharbor-web
supabase gen types typescript --linked > lib/database.types.ts
```

### Issue: Environment variables not matching

**Symptom:** Python writes to different Supabase than Next.js reads

**Solution:**
```bash
# Verify both use same Supabase URL
echo $SUPABASE_URL  # In Python
cat .env.local | grep SUPABASE_URL  # In Next.js
```

### Issue: Can't find documentation

**Solution:**
```
Add to redditharbor-web/README.md:
üìö Documentation: See github.com/ai-rio/redditharbor/docs
```

---

## Conclusion

**Recommended Structure: Polyrepo (2 Separate Repositories)**

**Reasoning:**
1. ‚úÖ Clean separation (Python vs Next.js)
2. ‚úÖ Independent deployment (GitHub Actions vs Vercel)
3. ‚úÖ Simple to understand
4. ‚úÖ Standard industry practice
5. ‚úÖ No monorepo tooling needed
6. ‚úÖ Minimal coupling via database

**Not Recommended:**
- ‚ùå Monorepo: Overkill, adds complexity
- ‚ùå Service-based: Way too many repos
- ‚ùå Hybrid: Awkward with Python + Node.js

**Next Steps:**
1. Keep `redditharbor` (Python) as-is
2. Create `redditharbor-web` (Next.js) new repo
3. Link repos in README
4. Deploy Python to GitHub Actions (already done)
5. Deploy Next.js to Vercel (new)
6. Supabase is the contract between them

---

**Document Status:** Complete
**Last Updated:** 2025-11-11
**Decision:** APPROVED - Use Polyrepo
