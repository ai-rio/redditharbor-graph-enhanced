# Docker & Production Setup

**Purpose**: Complete production-ready deployment configuration for the RedditHarbor FastAPI backend, including Docker optimization, reverse proxy setup, and infrastructure configuration.

---

## Production Architecture

### High-Level Architecture
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Nginx Proxy   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   FastAPI App   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Redis Cache   ‚îÇ
‚îÇ  (Port 80/443)  ‚îÇ    ‚îÇ (Port 8000)     ‚îÇ    ‚îÇ (Port 6379)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                                ‚ñº
                       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                       ‚îÇ   Supabase DB   ‚îÇ
                       ‚îÇ   (External)    ‚îÇ
                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Infrastructure Components
- **Nginx**: Reverse proxy, SSL termination, static file serving
- **FastAPI**: Application server (Gunicorn + Uvicorn workers)
- **Redis**: Rate limiting, caching, session storage
- **Supabase**: Primary database (external service)
- **Monitoring**: Health checks, metrics collection

---

## Docker Configuration

### Multi-stage Dockerfile

Based on the extracted boilerplate, optimized for RedditHarbor:

```dockerfile
# api/Dockerfile
# Multi-stage build for optimal production deployment

# ===== Stage 1: Build Dependencies =====
FROM python:3.11-slim as requirements-stage

WORKDIR /tmp

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Install poetry for dependency management
RUN pip install --no-cache-dir poetry==1.7.1

# Copy dependency files
COPY api/pyproject.toml api/poetry.lock* /tmp/

# Export requirements with version pinning
RUN poetry export -f requirements.txt \
    --output requirements.txt \
    --without-hashes \
    --with dev

# ===== Stage 2: Production Image =====
FROM python:3.11-slim as production

# Create non-root user for security
RUN groupadd -r redditapi && useradd -r -g redditapi redditapi

# Install runtime dependencies
RUN apt-get update && apt-get install -y \
    curl \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# Set working directory
WORKDIR /app

# Copy requirements from build stage
COPY --from=requirements-stage /tmp/requirements.txt /app/requirements.txt

# Install Python dependencies
RUN pip install --no-cache-dir --upgrade pip \
    && pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY --chown=redditapi:redditapi api /app/api
COPY --chown=redditapi:redditapi config /app/config
COPY --chown=redditapi:redditapi core /app/core

# Create necessary directories
RUN mkdir -p /app/logs /app/tmp \
    && chown -R redditapi:redditapi /app/logs /app/tmp

# Switch to non-root user
USER redditapi

# Expose application port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=40s --retries=3 \
    CMD curl -f http://localhost:8000/api/v1/health || exit 1

# Set environment variables
ENV PYTHONPATH=/app
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1

# Start application
CMD ["gunicorn", "api.main:app", \
     "-w", "4", \
     "-k", "uvicorn.workers.UvicornWorker", \
     "--bind", "0.0.0.0:8000", \
     "--access-logfile", "-", \
     "--error-logfile", "-", \
     "--log-level", "info"]
```

### Development Dockerfile

```dockerfile
# api/Dockerfile.dev
# Development-optimized Dockerfile with hot reload

FROM python:3.11-slim

# Install development dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    git \
    && rm -rf /var/lib/apt/lists/*

# Set working directory
WORKDIR /app

# Install Python dependencies
COPY api/requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Install development dependencies
RUN pip install --no-cache-dir pytest pytest-asyncio black ruff mypy

# Copy application code
COPY api /app/api
COPY config /app/config
COPY core /app/core

# Set environment variables
ENV PYTHONPATH=/app
ENV PYTHONUNBUFFERED=1
ENV ENVIRONMENT=development

# Expose ports
EXPOSE 8000

# Start development server with hot reload
CMD ["uvicorn", "api.main:app", \
     "--host", "0.0.0.0", \
     "--port", "8000", \
     "--reload", \
     "--log-level", "debug"]
```

---

## Docker Compose Configuration

### Production Docker Compose

Based on the extracted boilerplate, enhanced for RedditHarbor:

```yaml
# docker-compose.yml
version: '3.8'

services:
  # ===== FastAPI Application =====
  api:
    build:
      context: .
      dockerfile: api/Dockerfile
      target: production
    container_name: redditapi-api
    restart: unless-stopped
    command: >
      gunicorn api.main:app
      -w 4
      -k uvicorn.workers.UvicornWorker
      --bind 0.0.0.0:8000
      --access-logfile -
      --error-logfile -
      --log-level info
      --timeout 300
      --keep-alive 2
      --max-requests 1000
      --max-requests-jitter 50
    env_file:
      - .env
      - .env.production
    environment:
      - REDIS_URL=redis://redis:6379
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - ENVIRONMENT=production
    ports:
      - "8000:8000"
    depends_on:
      redis:
        condition: service_healthy
    volumes:
      - api-logs:/app/logs
      - api-tmp:/app/tmp
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'
    networks:
      - redditapi-network

  # ===== Redis Cache & Rate Limiting =====
  redis:
    image: redis:7-alpine
    container_name: redditapi-redis
    restart: unless-stopped
    command: redis-server /usr/local/etc/redis/redis.conf
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
      - ./config/redis.conf:/usr/local/etc/redis/redis.conf:ro
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
    networks:
      - redditapi-network

  # ===== Nginx Reverse Proxy =====
  nginx:
    image: nginx:alpine
    container_name: redditapi-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./config/nginx.conf:/etc/nginx/conf.d/default.conf:ro
      - ./config/ssl:/etc/nginx/ssl:ro
      - nginx-logs:/var/log/nginx
    depends_on:
      api:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.25'
        reservations:
          memory: 128M
          cpus: '0.1'
    networks:
      - redditapi-network

  # ===== Monitoring (Optional) =====
  prometheus:
    image: prom/prometheus:latest
    container_name: redditapi-prometheus
    restart: unless-stopped
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    ports:
      - "9090:9090"
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    profiles:
      - monitoring
    networks:
      - redditapi-network

  grafana:
    image: grafana/grafana:latest
    container_name: redditapi-grafana
    restart: unless-stopped
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
    volumes:
      - grafana-data:/var/lib/grafana
      - ./config/grafana/provisioning:/etc/grafana/provisioning
    depends_on:
      - prometheus
    profiles:
      - monitoring
    networks:
      - redditapi-network

# ===== Volumes =====
volumes:
  redis-data:
    driver: local
  api-logs:
    driver: local
  api-tmp:
    driver: local
  nginx-logs:
    driver: local
  prometheus-data:
    driver: local
  grafana-data:
    driver: local

# ===== Networks =====
networks:
  redditapi-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
```

### Development Docker Compose

```yaml
# docker-compose.dev.yml
version: '3.8'

services:
  api:
    build:
      context: .
      dockerfile: api/Dockerfile.dev
    container_name: redditapi-api-dev
    command: uvicorn api.main:app --host 0.0.0.0 --port 8000 --reload
    env_file:
      - .env
    environment:
      - ENVIRONMENT=development
      - DEBUG=true
      - REDIS_URL=redis://redis:6379
    ports:
      - "8000:8000"
    volumes:
      - .:/app
      - api-dev-logs:/app/logs
    depends_on:
      - redis
    networks:
      - redditapi-dev-network

  redis:
    image: redis:7-alpine
    container_name: redditapi-redis-dev
    ports:
      - "6379:6379"
    volumes:
      - redis-dev-data:/data
    networks:
      - redditapi-dev-network

  redis-commander:
    image: rediscommander/redis-commander:latest
    container_name: redditapi-redis-commander
    environment:
      - REDIS_HOSTS=local:redis:6379
    ports:
      - "8081:8081"
    depends_on:
      - redis
    networks:
      - redditapi-dev-network

volumes:
  redis-dev-data:
  api-dev-logs:

networks:
  redditapi-dev-network:
    driver: bridge
```

---

## Nginx Configuration

### Production Nginx Configuration

```nginx
# config/nginx.conf
# Optimized Nginx configuration for RedditHarbor API

# Upstream backend servers
upstream redditapi_backend {
    least_conn;
    server api:8000 max_fails=3 fail_timeout=30s;
    keepalive 32;
}

# Rate limiting zone
limit_req_zone $binary_remote_addr zone=api_limit:10m rate=60r/m;
limit_req_zone $binary_remote_addr zone=pipeline_limit:10m rate=5r/m;
limit_req_zone $binary_remote_addr zone=analysis_limit:10m rate=20r/m;

# HTTP to HTTPS redirect (production)
server {
    listen 80;
    server_name api.redditharbor.com;
    return 301 https://$server_name$request_uri;
}

# HTTPS server
server {
    listen 443 ssl http2;
    server_name api.redditharbor.com;

    # SSL configuration
    ssl_certificate /etc/nginx/ssl/cert.pem;
    ssl_certificate_key /etc/nginx/ssl/key.pem;
    ssl_session_timeout 1d;
    ssl_session_cache shared:SSL:50m;
    ssl_session_tickets off;

    # Modern SSL configuration
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384;
    ssl_prefer_server_ciphers off;

    # HSTS
    add_header Strict-Transport-Security "max-age=63072000" always;

    # Security headers
    add_header X-Frame-Options "DENY" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header X-XSS-Protection "1; mode=block" always;
    add_header Referrer-Policy "strict-origin-when-cross-origin" always;
    add_header Content-Security-Policy "default-src 'self'; script-src 'self' 'unsafe-inline'; style-src 'self' 'unsafe-inline'; img-src 'self' data: https:; font-src 'self'; connect-src 'self';" always;

    # Client max body size (for file uploads)
    client_max_body_size 10M;

    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types
        application/json
        application/javascript
        text/css
        text/plain
        text/markdown;

    # API endpoints with specific rate limits
    location /api/v1/pipeline {
        limit_req zone=pipeline_limit burst=3 nodelay;

        proxy_pass http://redditapi_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # Timeout settings for long-running operations
        proxy_connect_timeout 60s;
        proxy_send_timeout 600s;
        proxy_read_timeout 600s;
    }

    location /api/v1/profiler {
        limit_req zone=analysis_limit burst=5 nodelay;

        proxy_pass http://redditapi_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        proxy_connect_timeout 30s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
    }

    # General API endpoints
    location /api/ {
        limit_req zone=api_limit burst=10 nodelay;

        proxy_pass http://redditapi_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # Connection settings
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;

        # Keepalive settings
        proxy_http_version 1.1;
        proxy_set_header Connection "";
    }

    # Health check endpoint (no rate limiting)
    location /api/v1/health {
        proxy_pass http://redditapi_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        access_log off;  # Don't log health checks
    }

    # API documentation
    location /docs {
        proxy_pass http://redditapi_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    # OpenAPI JSON
    location /openapi.json {
        proxy_pass http://redditapi_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    # Root endpoint
    location / {
        return 301 /docs;
    }

    # Logging
    access_log /var/log/nginx/access.log;
    error_log /var/log/nginx/error.log warn;
}

# Development server (HTTP only)
server {
    listen 80;
    server_name localhost 127.0.0.1;

    # Basic security headers for development
    add_header X-Frame-Options "DENY" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header X-XSS-Protection "1; mode=block" always;

    # Proxy all requests to backend
    location / {
        proxy_pass http://redditapi_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # Longer timeouts for development
        proxy_connect_timeout 60s;
        proxy_send_timeout 300s;
        proxy_read_timeout 300s;
    }
}
```

---

## Redis Configuration

### Production Redis Configuration

```redis
# config/redis.conf
# Optimized Redis configuration for RedditHarbor rate limiting

# === Network Settings ===
bind 0.0.0.0
port 6379
tcp-backlog 511
timeout 0
tcp-keepalive 60

# === Memory Management ===
# Limit memory usage (adjust based on available resources)
maxmemory 512mb
maxmemory-policy allkeys-lru

# === Persistence Settings ===
# Minimal persistence for rate limiting data
save 900 1    # Save if at least 1 key changed in 15 minutes
save 300 10   # Save if at least 10 keys changed in 5 minutes
save 60 10000 # Save if at least 10000 keys changed in 1 minute

# RDB persistence
rdbcompression yes
rdbchecksum yes
dbfilename dump.rdb
dir /data

# Disable AOF (not needed for rate limiting)
appendonly no

# === Performance Optimizations ===
# Database number (we only need one)
databases 1

# Lazy expiration (better for rate limiting)
lazyexpire yes

# Slow log configuration
slowlog-log-slower-than 1000
slowlog-max-len 256

# Client connection limits
maxclients 10000

# === Security Settings ===
# Require authentication if REDIS_PASSWORD is set
# requirepass your-password-here

# Disable dangerous commands
rename-command FLUSHDB ""
rename-command FLUSHALL ""
rename-command KEYS ""
rename-command CONFIG "CONFIG_b835c3f8a5d2e7f1"

# === Logging ===
loglevel notice
logfile ""

# === Additional Settings ===
# Disable transparent huge pages
disable-thp yes

# Hash table settings
hash-max-ziplist-entries 512
hash-max-ziplist-value 64
list-max-ziplist-size -2
set-max-intset-entries 512
zset-max-ziplist-entries 128
zset-max-ziplist-value 64
```

---

## Environment Configuration

### Production Environment Variables

```bash
# .env.production
# Production environment configuration

# === Application Settings ===
APP_NAME="RedditHarbor API"
APP_VERSION="2.0.0"
ENVIRONMENT=production
DEBUG=false

# === Security Settings ===
# API Keys (use secret management in production)
REDDIT_HARBOR_API_KEY=${REDDIT_HARBOR_API_KEY}
JWT_SECRET_KEY=${JWT_SECRET_KEY}

# CORS Settings (restrict to your domains)
CORS_ORIGINS=["https://app.redditharbor.com", "https://api.redditharbor.com"]

# === Database Configuration ===
# Supabase (from environment or secret management)
SUPABASE_URL=${SUPABASE_URL}
SUPABASE_KEY=${SUPABASE_KEY}

# === Redis Configuration ===
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=${REDIS_PASSWORD}
REDIS_DB=0

# === Rate Limiting Settings ===
DEFAULT_RATE_LIMIT=60/minute
PIPELINE_RATE_LIMIT=5/minute
ANALYSIS_RATE_LIMIT=20/minute

# === Logging Configuration ===
LOG_LEVEL=INFO
LOG_FORMAT=json
LOG_FILE=/app/logs/api.log

# === Performance Settings ===
# Gunicorn workers (2 x CPU cores + 1)
WORKERS=4
WORKER_CLASS=uvicorn.workers.UvicornWorker
WORKER_CONNECTIONS=1000
MAX_REQUESTS=1000
MAX_REQUESTS_JITTER=50
WORKER_TIMEOUT=300

# === Monitoring Settings ===
PROMETHEUS_ENABLED=true
METRICS_PORT=9090
HEALTH_CHECK_INTERVAL=30

# === SSL/TLS Settings ===
SSL_CERT_PATH=/etc/nginx/ssl/cert.pem
SSL_KEY_PATH=/etc/nginx/ssl/key.pem

# === External Service URLs ===
MONITORING_WEBHOOK=${MONITORING_WEBHOOK}
ERROR_WEBHOOK=${ERROR_WEBHOOK}
```

### Development Environment Variables

```bash
# .env.development
# Development environment configuration

# === Application Settings ===
APP_NAME="RedditHarbor API"
APP_VERSION="2.0.0"
ENVIRONMENT=local
DEBUG=true

# === Security Settings ===
REDDIT_HARBOR_API_KEY=dev-api-key-change-in-production
JWT_SECRET_KEY=dev-jwt-secret-change-in-production

# CORS Settings (allow all for development)
CORS_ORIGINS=["http://localhost:3000", "http://127.0.0.1:3000"]

# === Database Configuration ===
SUPABASE_URL=http://127.0.0.1:54321
SUPABASE_KEY=your-local-supabase-key

# === Redis Configuration ===
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0

# === Rate Limiting Settings ===
DEFAULT_RATE_LIMIT=100/minute
PIPELINE_RATE_LIMIT=10/minute
ANALYSIS_RATE_LIMIT=30/minute

# === Logging Configuration ===
LOG_LEVEL=DEBUG
LOG_FORMAT=console

# === Performance Settings ===
WORKERS=1
WORKER_CLASS=uvicorn.workers.UvicornWorker
WORKER_CONNECTIONS=1000

# === Development Settings ===
RELOAD=true
ACCESS_LOG=true
```

---

## Deployment Scripts

### Production Deployment Script

```bash
#!/bin/bash
# scripts/deploy-production.sh
# Production deployment script for RedditHarbor API

set -e  # Exit on any error

# Configuration
PROJECT_NAME="redditapi"
DOCKER_REGISTRY="your-registry.com"
VERSION=${1:-latest}
ENVIRONMENT="production"

echo "üöÄ Deploying RedditHarbor API v$VERSION to $ENVIRONMENT"

# === Pre-deployment Checks ===
echo "üîç Running pre-deployment checks..."

# Check if required environment variables are set
required_vars=("REDDIT_HARBOR_API_KEY" "SUPABASE_URL" "SUPABASE_KEY")
for var in "${required_vars[@]}"; do
    if [ -z "${!var}" ]; then
        echo "‚ùå Error: $var is not set"
        exit 1
    fi
done

# Check if Docker is running
if ! docker info > /dev/null 2>&1; then
    echo "‚ùå Error: Docker is not running"
    exit 1
fi

# Check if docker-compose is installed
if ! command -v docker-compose &> /dev/null; then
    echo "‚ùå Error: docker-compose is not installed"
    exit 1
fi

# === Backup Current Version ===
echo "üíæ Backing up current deployment..."
docker-compose down
docker tag redditapi-api:latest redditapi-api:backup-$(date +%Y%m%d-%H%M%S)

# === Build New Images ===
echo "üèóÔ∏è Building Docker images..."
docker-compose build --no-cache api

# === Database Migrations (if needed) ===
echo "üóÑÔ∏è Running database migrations..."
# Add migration commands here if needed
# docker-compose run --rm api python -m alembic upgrade head

# === Start New Deployment ===
echo "üöÄ Starting new deployment..."
docker-compose -f docker-compose.yml -f docker-compose.production.yml up -d

# === Health Checks ===
echo "üè• Running health checks..."
sleep 30  # Wait for services to start

# Check API health
if curl -f http://localhost/api/v1/health > /dev/null 2>&1; then
    echo "‚úÖ API health check passed"
else
    echo "‚ùå API health check failed"
    docker-compose logs api
    exit 1
fi

# Check Redis health
if docker-compose exec -T redis redis-cli ping > /dev/null 2>&1; then
    echo "‚úÖ Redis health check passed"
else
    echo "‚ùå Redis health check failed"
    docker-compose logs redis
    exit 1
fi

# === Cleanup ===
echo "üßπ Cleaning up old images..."
docker image prune -f

# === Deployment Summary ===
echo "üìä Deployment Summary:"
echo "   Version: $VERSION"
echo "   Environment: $ENVIRONMENT"
echo "   Status: ‚úÖ Success"
echo "   API URL: https://api.redditharbor.com"
echo "   Health Check: https://api.redditharbor.com/api/v1/health"

echo "üéâ Deployment completed successfully!"
```

### Development Setup Script

```bash
#!/bin/bash
# scripts/setup-development.sh
# Development environment setup script

set -e

echo "üõ†Ô∏è Setting up RedditHarbor API development environment"

# === Check Prerequisites ===
echo "üîç Checking prerequisites..."

# Check Python version
python_version=$(python3 --version 2>&1 | grep -Po '(?<=Python )\d+\.\d+' || echo "0.0")
if (( $(echo "$python_version < 3.11" | bc -l) )); then
    echo "‚ùå Error: Python 3.11+ is required (found $python_version)"
    exit 1
fi

# Check if Docker is running
if ! docker info > /dev/null 2>&1; then
    echo "‚ùå Error: Docker is not running"
    exit 1
fi

# Check if redis-cli is available
if ! command -v redis-cli &> /dev/null; then
    echo "‚ö†Ô∏è Warning: redis-cli is not installed"
fi

# === Setup Environment ===
echo "üìÅ Setting up environment..."

# Create .env file if it doesn't exist
if [ ! -f .env ]; then
    echo "Creating .env file..."
    cp .env.example .env.development
    echo "Please edit .env.development with your configuration"
fi

# === Install Dependencies ===
echo "üì¶ Installing dependencies..."

# Create virtual environment if it doesn't exist
if [ ! -d "venv" ]; then
    echo "Creating virtual environment..."
    python3 -m venv venv
fi

# Activate virtual environment
source venv/bin/activate

# Install Python dependencies
echo "Installing Python dependencies..."
pip install --upgrade pip
pip install -r api/requirements.txt

# Install development dependencies
pip install pytest pytest-asyncio black ruff mypy

# === Start Services ===
echo "üöÄ Starting development services..."

# Start Redis
echo "Starting Redis..."
docker-compose -f docker-compose.dev.yml up -d redis

# Wait for Redis to start
echo "Waiting for Redis to start..."
sleep 5

# Check Redis connection
if docker-compose -f docker-compose.dev.yml exec -T redis redis-cli ping > /dev/null 2>&1; then
    echo "‚úÖ Redis is running"
else
    echo "‚ùå Redis failed to start"
    exit 1
fi

# === Run Tests ===
echo "üß™ Running initial tests..."
python -m pytest tests/ -v

# === Setup Complete ===
echo "üéâ Development environment setup complete!"
echo ""
echo "To start the development server:"
echo "  source venv/bin/activate"
echo "  docker-compose -f docker-compose.dev.yml up"
echo ""
echo "API will be available at: http://localhost:8000"
echo "API documentation: http://localhost:8000/docs"
echo "Redis Commander: http://localhost:8081"
```

---

## Monitoring and Logging

### Prometheus Configuration

```yaml
# config/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "rules/*.yml"

scrape_configs:
  - job_name: 'redditapi'
    static_configs:
      - targets: ['api:8000']
    metrics_path: '/metrics'
    scrape_interval: 30s

  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']
    scrape_interval: 30s

  - job_name: 'nginx'
    static_configs:
      - targets: ['nginx:80']
    scrape_interval: 30s

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093
```

### Health Check Endpoint Implementation

```python
# api/routers/monitoring.py
from fastapi import APIRouter, Depends, HTTPException
from datetime import datetime, timedelta
from typing import Dict, Any
from api.core.auth import verify_api_key
from api.core.redis_connection import redis_manager
from core.pipeline.orchestrator import OpportunityPipeline
import logging

router = APIRouter()
logger = logging.getLogger(__name__)

class HealthChecker:
    """Comprehensive health checking for API services."""

    @staticmethod
    async def check_database_health() -> Dict[str, Any]:
        """Check database connectivity."""
        try:
            # Test Supabase connection
            from supabase import create_client
            from config.settings import SUPABASE_URL, SUPABASE_KEY

            client = create_client(SUPABASE_URL, SUPABASE_KEY)
            result = client.table('redditor').select('id').limit(1).execute()

            return {
                "status": "healthy",
                "response_time_ms": 0,  # Add timing if needed
                "details": "Database connection successful"
            }
        except Exception as e:
            return {
                "status": "unhealthy",
                "error": str(e),
                "details": "Database connection failed"
            }

    @staticmethod
    async def check_redis_health() -> Dict[str, Any]:
        """Check Redis connectivity."""
        try:
            client = await redis_manager.get_client()
            start_time = datetime.now()
            await client.ping()
            response_time = (datetime.now() - start_time).total_seconds() * 1000

            return {
                "status": "healthy",
                "response_time_ms": response_time,
                "details": "Redis connection successful"
            }
        except Exception as e:
            return {
                "status": "unhealthy",
                "error": str(e),
                "details": "Redis connection failed"
            }

    @staticmethod
    async def check_pipeline_health() -> Dict[str, Any]:
        """Check pipeline service health."""
        try:
            # Test pipeline initialization
            from core.pipeline.config import PipelineConfig
            config = PipelineConfig(data_source="database", limit=1)

            # Don't actually run the pipeline, just test initialization
            return {
                "status": "healthy",
                "details": "Pipeline service ready"
            }
        except Exception as e:
            return {
                "status": "unhealthy",
                "error": str(e),
                "details": "Pipeline service initialization failed"
            }

@router.get("/api/v1/health", tags=["monitoring"])
async def health_check():
    """
    Comprehensive health check for all API services.

    Returns the health status of all dependent services and overall API health.
    This endpoint does not require authentication for monitoring purposes.
    """
    health_checker = HealthChecker()

    # Check all services concurrently
    db_health, redis_health, pipeline_health = await asyncio.gather(
        health_checker.check_database_health(),
        health_checker.check_redis_health(),
        health_checker.check_pipeline_health(),
        return_exceptions=True
    )

    # Determine overall health
    services = {
        "database": db_health if not isinstance(db_health, Exception) else {
            "status": "unhealthy",
            "error": str(db_health)
        },
        "redis": redis_health if not isinstance(redis_health, Exception) else {
            "status": "unhealthy",
            "error": str(redis_health)
        },
        "pipeline": pipeline_health if not isinstance(pipeline_health, Exception) else {
            "status": "unhealthy",
            "error": str(pipeline_health)
        }
    }

    # Calculate overall status
    unhealthy_services = [
        name for name, health in services.items()
        if health.get("status") != "healthy"
    ]

    overall_status = "healthy" if not unhealthy_services else "unhealthy"

    return {
        "status": overall_status,
        "version": "2.0.0",
        "timestamp": datetime.utcnow().isoformat(),
        "uptime_seconds": time.time() - start_time,
        "services": services,
        "unhealthy_services": unhealthy_services
    }

@router.get("/api/v1/metrics", tags=["monitoring"])
async def get_metrics(api_key: str = Depends(verify_api_key)):
    """
    Get API performance metrics and statistics.

    This endpoint provides detailed metrics about API performance,
    usage statistics, and system health.
    """
    try:
        # Get rate limiting metrics
        from api.monitoring.rate_limit_monitor import rate_limit_monitor
        rate_limit_metrics = rate_limit_monitor.get_metrics()

        # Get Redis memory usage
        redis_memory = await health_checker.get_redis_memory_usage()

        return {
            "performance": {
                "request_count_24h": 1250,
                "average_response_time_ms": 245,
                "error_rate_24h": 0.02,
                "uptime_percentage": 99.9
            },
            "business": {
                "cost_savings_ytd": 2800.00,
                "total_analyzed": 5420,
                "pipeline_runs_today": 12,
                "opportunities_found_today": 8
            },
            "rate_limiting": rate_limit_metrics,
            "system": {
                "redis_memory_usage": redis_memory,
                "active_connections": 45,
                "cpu_usage": 0.35,
                "memory_usage": 0.62
            },
            "timestamp": datetime.utcnow().isoformat()
        }

    except Exception as e:
        logger.error(f"Failed to get metrics: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Failed to retrieve metrics: {str(e)}"
        )
```

---

## SSL/TLS Configuration

### Let's Encrypt Certificate Setup

```bash
#!/bin/bash
# scripts/setup-ssl.sh
# Setup SSL certificates with Let's Encrypt

set -e

DOMAIN="api.redditharbor.com"
EMAIL="admin@redditharbor.com"

echo "üîí Setting up SSL certificates for $DOMAIN"

# === Install Certbot ===
echo "üì¶ Installing Certbot..."
sudo apt-get update
sudo apt-get install -y certbot python3-certbot-nginx

# === Generate Certificate ===
echo "üîë Generating SSL certificate..."
sudo certbot certonly --nginx \
    --non-interactive \
    --agree-tos \
    --email "$EMAIL" \
    --domains "$DOMAIN"

# === Setup Certificate Renewal ===
echo "‚è∞ Setting up certificate renewal..."
sudo crontab -l | { cat; echo "0 12 * * * /usr/bin/certbot renew --quiet"; } | sudo crontab -

# === Copy Certificates to Nginx Directory ===
echo "üìÅ Copying certificates..."
sudo mkdir -p /etc/nginx/ssl
sudo cp /etc/letsencrypt/live/$DOMAIN/fullchain.pem /etc/nginx/ssl/cert.pem
sudo cp /etc/letsencrypt/live/$DOMAIN/privkey.pem /etc/nginx/ssl/key.pem
sudo chown -R root:root /etc/nginx/ssl
sudo chmod 600 /etc/nginx/ssl/key.pem
sudo chmod 644 /etc/nginx/ssl/cert.pem

# === Test Nginx Configuration ===
echo "üß™ Testing Nginx configuration..."
sudo nginx -t

# === Reload Nginx ===
echo "üîÑ Reloading Nginx..."
sudo systemctl reload nginx

echo "‚úÖ SSL certificate setup complete!"
echo "Certificate will auto-renew via cron job."
```

---

## Performance Optimization

### Production Performance Tuning

```yaml
# docker-compose.production.yml
# Production-specific overrides for performance optimization

version: '3.8'

services:
  api:
    deploy:
      replicas: 3  # Horizontal scaling
      resources:
        limits:
          memory: 1.5G
          cpus: '1.5'
        reservations:
          memory: 1G
          cpus: '1.0'
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.api.rule=Host(`api.redditharbor.com`)"
        - "traefik.http.routers.api.tls=true"
        - "traefik.http.services.api.loadbalancer.server.port=8000"

  redis:
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.75'
        reservations:
          memory: 512M
          cpus: '0.5'

  nginx:
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
        reservations:
          memory: 128M
          cpus: '0.25'
```

This comprehensive production deployment configuration provides enterprise-ready deployment for the RedditHarbor API with proper security, monitoring, scaling, and performance optimization.