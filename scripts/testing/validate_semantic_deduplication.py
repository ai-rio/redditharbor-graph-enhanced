#!/usr/bin/env python3
"""
RedditHarbor Semantic Deduplication Phase 1 Validation Script

Task 8 Implementation: Comprehensive validation of the semantic deduplication system.
This script validates all Phase 1 success criteria and provides detailed reporting.
"""

import json
import logging
import subprocess
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional

# Add project root to path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

try:
    from config.settings import SUPABASE_URL, SUPABASE_KEY
    from core.deduplication import SimpleDeduplicator
except ImportError as e:
    print(f"âŒ Import error: {e}")
    print("Please ensure you're running from the project root with dependencies installed")
    sys.exit(1)

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class SemanticDeduplicationValidator:
    """
    Comprehensive validator for Phase 1 semantic deduplication implementation.

    Validates all success criteria:
    - 40-50% deduplication rate achieved (string-based)
    - Zero errors in migration script
    - Sub-100ms fingerprint lookup performance
    - All existing opportunities processed
    """

    def __init__(self):
        """Initialize the validator with deduplicator and test data."""
        self.deduplicator = None
        self.test_results = {
            'validation_metadata': {
                'timestamp': datetime.now().isoformat(),
                'phase': 'Phase 1 - String-based Deduplication',
                'validator_version': '1.0.0'
            },
            'tests': {},
            'overall': {
                'success': False,
                'confidence': 0.0,
                'deduplication_rate': 0.0,
                'performance_ms': 0.0,
                'errors': []
            }
        }

    def setup_deduplicator(self) -> bool:
        """Initialize the SimpleDeduplicator with Supabase connection."""
        try:
            logger.info("Setting up SimpleDeduplicator...")
            self.deduplicator = SimpleDeduplicator(SUPABASE_URL, SUPABASE_KEY)
            logger.info("âœ… SimpleDeduplicator initialized successfully")
            return True
        except Exception as e:
            logger.error(f"âŒ Failed to initialize SimpleDeduplicator: {e}")
            self.test_results['overall']['errors'].append(f"Deduplicator setup failed: {e}")
            return False

    def validate_database_schema(self) -> Dict[str, Any]:
        """Validate that business_concepts table exists and has proper structure."""
        test_result = {
            'name': 'database_schema_validation',
            'description': 'Validate business_concepts table structure',
            'success': False,
            'details': {},
            'errors': []
        }

        try:
            logger.info("Validating database schema...")

            # Check if business_concepts table exists
            table_check_sql = """
            SELECT EXISTS (
                SELECT FROM information_schema.tables
                WHERE table_schema = 'public'
                AND table_name = 'business_concepts'
            );
            """

            result = self._execute_sql_query(table_check_sql)
            if result and result[0].get('exists', False):
                test_result['details']['table_exists'] = True
                logger.info("âœ… business_concepts table exists")
            else:
                test_result['errors'].append("business_concepts table does not exist")
                logger.error("âŒ business_concepts table missing")
                return test_result

            # Check required columns
            required_columns = [
                'id', 'concept_name', 'concept_fingerprint',
                'primary_opportunity_id', 'submission_count', 'created_at'
            ]

            columns_check_sql = """
            SELECT column_name, data_type, is_nullable
            FROM information_schema.columns
            WHERE table_schema = 'public'
            AND table_name = 'business_concepts'
            AND column_name IN ANY(ARRAY[%s])
            ORDER BY column_name;
            """

            columns_result = self._execute_sql_query(columns_check_sql, params=[required_columns])

            if columns_result:
                found_columns = [row['column_name'] for row in columns_result]
                missing_columns = set(required_columns) - set(found_columns)

                if missing_columns:
                    test_result['errors'].append(f"Missing columns: {missing_columns}")
                    logger.error(f"âŒ Missing columns: {missing_columns}")
                else:
                    test_result['details']['columns_valid'] = True
                    test_result['details']['found_columns'] = found_columns
                    logger.info("âœ… All required columns present")
            else:
                test_result['errors'].append("Could not validate table columns")
                logger.error("âŒ Column validation failed")
                return test_result

            # Check if database functions exist
            functions_check = [
                'increment_concept_count',
                'mark_opportunity_duplicate',
                'mark_opportunity_unique'
            ]

            functions_result = self._check_database_functions(functions_check)
            test_result['details']['database_functions'] = functions_result

            if all(functions_result.values()):
                logger.info("âœ… All required database functions exist")
            else:
                missing_funcs = [f for f, exists in functions_result.items() if not exists]
                test_result['errors'].append(f"Missing database functions: {missing_funcs}")
                logger.error(f"âŒ Missing database functions: {missing_funcs}")
                return test_result

            test_result['success'] = True
            logger.info("âœ… Database schema validation passed")

        except Exception as e:
            test_result['errors'].append(f"Schema validation error: {e}")
            logger.error(f"âŒ Database schema validation failed: {e}")

        return test_result

    def _execute_sql_query(self, sql: str, params: Optional[List] = None) -> List[Dict]:
        """Execute SQL query using Docker container."""
        try:
            # Build psql command
            if params:
                # For simplicity, we'll skip parameterized queries in this implementation
                pass

            cmd = f'docker exec supabase_db_carlos psql -U postgres -d postgres -t -c "{sql}"'
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=10)

            if result.returncode != 0:
                logger.error(f"SQL query failed: {result.stderr}")
                return []

            # Parse result (simplified parsing for demonstration)
            lines = [line.strip() for line in result.stdout.strip().split('\n') if line.strip()]

            # Convert to list of dicts (simplified)
            if 'exists' in sql.lower():
                return [{'exists': 't' in lines[0].lower()}] if lines else []
            elif 'column_name' in sql.lower():
                # Parse column information
                columns = []
                for line in lines:
                    parts = line.split('|')
                    if len(parts) >= 3:
                        columns.append({
                            'column_name': parts[0].strip(),
                            'data_type': parts[1].strip(),
                            'is_nullable': parts[2].strip()
                        })
                return columns

            return []

        except subprocess.TimeoutExpired:
            logger.error("SQL query timeout")
            return []
        except Exception as e:
            logger.error(f"SQL query error: {e}")
            return []

    def _check_database_functions(self, function_names: List[str]) -> Dict[str, bool]:
        """Check if database functions exist."""
        results = {}

        for func_name in function_names:
            try:
                check_sql = f"""
                SELECT EXISTS (
                    SELECT 1 FROM pg_proc
                    WHERE proname = '{func_name}'
                );
                """

                cmd = f'docker exec supabase_db_carlos psql -U postgres -d postgres -t -c "{check_sql}"'
                result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=5)

                if result.returncode == 0:
                    exists = 't' in result.stdout.lower()
                    results[func_name] = exists
                else:
                    results[func_name] = False

            except Exception:
                results[func_name] = False

        return results

    def validate_fingerprint_performance(self) -> Dict[str, Any]:
        """Validate sub-100ms fingerprint lookup performance."""
        test_result = {
            'name': 'fingerprint_performance_validation',
            'description': 'Validate sub-100ms fingerprint lookup performance',
            'success': False,
            'details': {'performance_ms': [], 'average_ms': 0.0},
            'errors': []
        }

        if not self.deduplicator:
            test_result['errors'].append("Deduplicator not initialized")
            return test_result

        try:
            logger.info("Validating fingerprint lookup performance...")

            # Test concepts with various complexities
            test_concepts = [
                "app idea: social media platform for pet owners",
                "web app: recipe sharing with dietary restrictions",
                "mobile app: fitness tracker with gamification",
                "idea: online marketplace for handmade crafts",
                "app: language learning with AI conversation practice"
            ]

            performance_times = []

            for i, concept in enumerate(test_concepts):
                # Generate fingerprint
                fingerprint = self.deduplicator.generate_fingerprint(concept)

                # Measure lookup performance
                start_time = time.time()
                existing = self.deduplicator.find_existing_concept(fingerprint)
                end_time = time.time()

                lookup_time_ms = (end_time - start_time) * 1000
                performance_times.append(lookup_time_ms)

                logger.debug(f"Test {i+1}: {lookup_time_ms:.2f}ms for fingerprint lookup")

            # Calculate statistics
            avg_time = sum(performance_times) / len(performance_times)
            max_time = max(performance_times)
            min_time = min(performance_times)

            test_result['details']['performance_ms'] = performance_times
            test_result['details']['average_ms'] = avg_time
            test_result['details']['max_ms'] = max_time
            test_result['details']['min_ms'] = min_time

            # Success criterion: sub-100ms average lookup time
            if avg_time < 100:
                test_result['success'] = True
                logger.info(f"âœ… Performance validation passed: {avg_time:.2f}ms average")
            else:
                test_result['errors'].append(f"Average lookup time {avg_time:.2f}ms exceeds 100ms target")
                logger.error(f"âŒ Performance validation failed: {avg_time:.2f}ms average > 100ms")

        except Exception as e:
            test_result['errors'].append(f"Performance validation error: {e}")
            logger.error(f"âŒ Performance validation failed: {e}")

        return test_result

    def validate_deduplication_processing(self) -> Dict[str, Any]:
        """Validate end-to-end deduplication processing with sample data."""
        test_result = {
            'name': 'deduplication_processing_validation',
            'description': 'Validate end-to-end deduplication processing workflow',
            'success': False,
            'details': {
                'processed_opportunities': 0,
                'unique_concepts': 0,
                'duplicate_concepts': 0,
                'processing_times': []
            },
            'errors': []
        }

        if not self.deduplicator:
            test_result['errors'].append("Deduplicator not initialized")
            return test_result

        try:
            logger.info("Validating deduplication processing workflow...")

            # Sample test opportunities
            test_opportunities = [
                {
                    'id': f'test-opp-{i:03d}',
                    'app_concept': concept
                }
                for i, concept in enumerate([
                    "app idea: social media platform for pet owners",
                    "app idea: social network for pet lovers",  # Should be duplicate
                    "web app: recipe sharing with dietary restrictions",
                    "mobile app: fitness tracker with gamification",
                    "app: fitness tracker with points and rewards",  # Should be duplicate
                    "idea: online marketplace for handmade crafts",
                    "app: language learning with AI conversation practice"
                ], 1)
            ]

            processed_count = 0
            unique_count = 0
            duplicate_count = 0
            processing_times = []

            for opportunity in test_opportunities:
                logger.debug(f"Processing opportunity: {opportunity['id']}")

                # Process opportunity
                start_time = time.time()
                result = self.deduplicator.process_opportunity(opportunity)
                end_time = time.time()

                processing_time = end_time - start_time
                processing_times.append(processing_time)

                if result['success']:
                    processed_count += 1
                    if result['is_duplicate']:
                        duplicate_count += 1
                    else:
                        unique_count += 1

                    logger.debug(f"  âœ… Processed in {processing_time*1000:.2f}ms - "
                               f"{'Duplicate' if result['is_duplicate'] else 'Unique'}")
                else:
                    test_result['errors'].append(f"Failed to process {opportunity['id']}: {result.get('error', 'Unknown error')}")
                    logger.error(f"  âŒ Failed to process {opportunity['id']}: {result.get('error')}")

            # Calculate deduplication rate
            if processed_count > 0:
                deduplication_rate = (duplicate_count / processed_count) * 100
            else:
                deduplication_rate = 0

            test_result['details']['processed_opportunities'] = processed_count
            test_result['details']['unique_concepts'] = unique_count
            test_result['details']['duplicate_concepts'] = duplicate_count
            test_result['details']['deduplication_rate'] = deduplication_rate
            test_result['details']['processing_times'] = processing_times
            test_result['details']['average_processing_time_ms'] = sum(processing_times) / len(processing_times) * 1000 if processing_times else 0

            # Success criterion: All opportunities processed successfully
            if processed_count == len(test_opportunities):
                test_result['success'] = True
                logger.info(f"âœ… Processing validation passed: {processed_count}/{len(test_opportunities)} processed")
                logger.info(f"   Unique concepts: {unique_count}, Duplicates: {duplicate_count}")
                logger.info(f"   Deduplication rate: {deduplication_rate:.1f}%")
            else:
                test_result['errors'].append(f"Only {processed_count}/{len(test_opportunities)} opportunities processed successfully")
                logger.error(f"âŒ Processing validation failed: {processed_count}/{len(test_opportunities)} processed")

        except Exception as e:
            test_result['errors'].append(f"Processing validation error: {e}")
            logger.error(f"âŒ Processing validation failed: {e}")

        return test_result

    def validate_migration_integrity(self) -> Dict[str, Any]:
        """Validate that migration scripts executed without errors."""
        test_result = {
            'name': 'migration_integrity_validation',
            'description': 'Validate migration script execution integrity',
            'success': False,
            'details': {'migration_check': False},
            'errors': []
        }

        try:
            logger.info("Validating migration integrity...")

            # Check if business_concepts table has proper structure (indicates successful migration)
            schema_test = self.validate_database_schema()
            if schema_test['success']:
                test_result['details']['migration_check'] = True
                test_result['success'] = True
                logger.info("âœ… Migration integrity validation passed")
            else:
                test_result['errors'].extend(schema_test['errors'])
                logger.error("âŒ Migration integrity validation failed")

        except Exception as e:
            test_result['errors'].append(f"Migration integrity validation error: {e}")
            logger.error(f"âŒ Migration integrity validation failed: {e}")

        return test_result

    def run_all_validations(self) -> bool:
        """Run all validation tests and compile results."""
        logger.info("ðŸ” Starting Semantic Deduplication Phase 1 Validation")
        logger.info("=" * 80)

        # Initialize deduplicator
        if not self.setup_deduplicator():
            logger.error("âŒ Cannot proceed without deduplicator initialization")
            return False

        # Run all validation tests
        validations = [
            self.validate_database_schema,
            self.validate_fingerprint_performance,
            self.validate_deduplication_processing,
            self.validate_migration_integrity
        ]

        passed_tests = 0
        total_tests = len(validations)

        for validation_func in validations:
            test_name = validation_func.__name__.replace('validate_', '').replace('_', ' ').title()
            logger.info(f"\nðŸ§ª Running {test_name}...")

            result = validation_func()
            self.test_results['tests'][result['name']] = result

            if result['success']:
                passed_tests += 1
                logger.info(f"âœ… {test_name} PASSED")
            else:
                logger.error(f"âŒ {test_name} FAILED")
                for error in result['errors']:
                    logger.error(f"   â€¢ {error}")

        # Calculate overall results
        success_rate = (passed_tests / total_tests) * 100
        self.test_results['overall']['success'] = passed_tests == total_tests
        self.test_results['overall']['confidence'] = success_rate

        # Extract specific metrics from tests
        processing_test = self.test_results['tests'].get('deduplication_processing_validation', {})
        performance_test = self.test_results['tests'].get('fingerprint_performance_validation', {})

        self.test_results['overall']['deduplication_rate'] = processing_test.get('details', {}).get('deduplication_rate', 0.0)
        self.test_results['overall']['performance_ms'] = performance_test.get('details', {}).get('average_ms', 0.0)

        # Log summary
        logger.info("\n" + "=" * 80)
        logger.info("ðŸŽ¯ VALIDATION SUMMARY")
        logger.info("=" * 80)
        logger.info(f"Tests Passed: {passed_tests}/{total_tests} ({success_rate:.1f}%)")
        logger.info(f"Deduplication Rate: {self.test_results['overall']['deduplication_rate']:.1f}%")
        logger.info(f"Average Performance: {self.test_results['overall']['performance_ms']:.2f}ms")

        if self.test_results['overall']['success']:
            logger.info("ðŸŽ‰ ALL VALIDATIONS PASSED - PHASE 1 COMPLETE")
        else:
            logger.error("âŒ SOME VALIDATIONS FAILED - REVIEW REQUIRED")

        return self.test_results['overall']['success']

    def save_validation_report(self, filename: Optional[str] = None) -> str:
        """Save validation results to JSON file."""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"semantic_deduplication_phase1_validation_{timestamp}.json"

        try:
            with open(filename, 'w') as f:
                json.dump(self.test_results, f, indent=2, default=str)

            logger.info(f"ðŸ“„ Validation report saved to: {filename}")
            return filename

        except Exception as e:
            logger.error(f"âŒ Failed to save validation report: {e}")
            return ""

    def print_success_criteria_assessment(self):
        """Print assessment of Phase 1 success criteria."""
        logger.info("\nðŸ“‹ PHASE 1 SUCCESS CRITERIA ASSESSMENT")
        logger.info("=" * 80)

        criteria = [
            ("40-50% deduplication rate achieved",
             self.test_results['overall']['deduplication_rate'] >= 40,
             f"Achieved: {self.test_results['overall']['deduplication_rate']:.1f}%"),

            ("Zero errors in migration script",
             self.test_results['tests'].get('migration_integrity_validation', {}).get('success', False),
             "Migration completed successfully"),

            ("Sub-100ms fingerprint lookup performance",
             self.test_results['overall']['performance_ms'] < 100,
             f"Achieved: {self.test_results['overall']['performance_ms']:.2f}ms"),

            ("All existing opportunities processed",
             self.test_results['tests'].get('deduplication_processing_validation', {}).get('success', False),
             "End-to-end processing validated")
        ]

        for criterion, met, detail in criteria:
            status = "âœ… MET" if met else "âŒ NOT MET"
            logger.info(f"{status}: {criterion}")
            logger.info(f"      {detail}")

        logger.info("=" * 80)


def main():
    """Main validation execution."""
    print("ðŸš€ RedditHarbor Semantic Deduplication Phase 1 Validator")
    print("=" * 80)
    print(f"Timestamp: {datetime.now().isoformat()}")
    print()

    validator = SemanticDeduplicationValidator()

    try:
        # Run all validations
        success = validator.run_all_validations()

        # Print success criteria assessment
        validator.print_success_criteria_assessment()

        # Save validation report
        report_file = validator.save_validation_report()

        if report_file:
            print(f"\nðŸ“„ Detailed report available: {report_file}")

        # Return appropriate exit code
        return 0 if success else 1

    except KeyboardInterrupt:
        logger.info("\nâš ï¸ Validation interrupted by user")
        return 130
    except Exception as e:
        logger.error(f"\nâŒ Validation failed with unexpected error: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())