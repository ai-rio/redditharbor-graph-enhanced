# RedditHarbor Graph Enhanced - Complete Docker Stack
# Includes Deep-Graph-MCP integration, monitoring, and full observability

version: '3.8'

services:
  # Main RedditHarbor Application with Graph Integration
  redditharbor:
    build: .
    container_name: redditharbor-graph-enhanced
    ports:
      - "8000:8000"
    environment:
      - REDDIT_CLIENT_ID=${REDDIT_CLIENT_ID}
      - REDDIT_CLIENT_SECRET=${REDDIT_CLIENT_SECRET}
      - REDDIT_USER_AGENT=RedditHarbor/1.0
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_KEY=${SUPABASE_KEY}
      - SUPABASE_SERVICE_KEY=${SUPABASE_SERVICE_KEY}
      - DEEP_GRAPH_PROJECT_ID=${DEEP_GRAPH_PROJECT_ID}
      - DEEP_GRAPH_API_KEY=${DEEP_GRAPH_API_KEY}
      - DEEP_GRAPH_ENDPOINT=https://api.deepgraph.co
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - ENVIRONMENT=production
      - DEBUG=false
      - LOG_LEVEL=INFO
      - ENABLE_PII_ANONYMIZATION=true
      - SECRET_KEY=${SECRET_KEY}
      - MAX_WORKERS=4
      - CACHE_TTL=3600
      - RATE_LIMIT_PER_MINUTE=100
      - JINA_API_KEY=${JINA_API_KEY}
      - AGNO_API_KEY=${AGNO_API_KEY}
    volumes:
      - ./logs:/app/logs
      - ./backups:/app/backups
      - ./reports:/app/reports
    depends_on:
      - redis
      - postgres
      - elasticsearch
    networks:
      - redditharbor-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Deep-Graph-MCP Analysis Service
  graph-analyzer:
    build: .
    container_name: redditharbor-graph-analyzer
    command: python -c "
from core.graph_integration import RedditHarborGraphAnalyzer
from core.graph_integration.dependencies import DependencyMapper
from core.graph_integration.refactoring import IntelligentRefactorer

# Initialize services
analyzer = RedditHarborGraphAnalyzer()
mapper = DependencyMapper()
refactorer = IntelligentRefactorer()

# Run continuous analysis
import time
while True:
    try:
        print('üîç Running graph analysis...')

        # Analyze dependencies
        graph_summary = mapper.build_dependency_graph()
        print(f'Nodes: {graph_summary[\"total_nodes\"]}, Edges: {graph_summary[\"total_edges\"]}')

        # Detect circular dependencies
        circular_deps = mapper.detect_circular_dependencies()
        if circular_deps:
            print(f'‚ö†Ô∏è Found {len(circular_deps)} circular dependencies')

        # Generate refactoring opportunities
        opportunities = analyzer.find_refactoring_opportunities()
        if opportunities:
            print(f'üí° Found {len(opportunities)} refactoring opportunities')

        # Visualize dependency graph
        try:
            graph_path = mapper.visualize_dependency_graph('dependency_graph.png')
            print(f'üìä Graph visualization saved to: {graph_path}')
        except Exception as e:
            print(f'‚ö†Ô∏è Graph visualization failed: {e}')

        # Wait for next analysis cycle
        time.sleep(3600)  # Analyze every hour

    except KeyboardInterrupt:
        print('üëã Graph analysis service stopped')
        break
    except Exception as e:
        print(f'‚ùå Analysis error: {e}')
        time.sleep(300)  # Wait 5 minutes before retrying
"
    environment:
      - DEEP_GRAPH_PROJECT_ID=${DEEP_GRAPH_PROJECT_ID}
      - DEEP_GRAPH_API_KEY=${DEEP_GRAPH_API_KEY}
      - REDDIT_CLIENT_ID=${REDDIT_CLIENT_ID}
      - REDDIT_CLIENT_SECRET=${REDDIT_CLIENT_SECRET}
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_KEY=${SUPABASE_KEY}
      - REDIS_URL=${REDIS_URL}
    volumes:
      - ./logs:/app/logs
      - ./reports:/app/reports
    depends_on:
      - redis
      - postgres
    networks:
      - redditharbor-network
    restart: unless-stopped

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: redditharbor-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
      - ./redis/redis.conf:/usr/local/etc/redis/redis.conf
    command: redis-server /usr/local/etc/redis/redis.conf
    networks:
      - redditharbor-network
    restart: unless-stopped

  # PostgreSQL Database (Enhanced)
  postgres:
    image: postgres:15-alpine
    container_name: redditharbor-postgres
    environment:
      - POSTGRES_DB=redditharbor
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    networks:
      - redditharbor-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Monitoring Stack
  prometheus:
    image: prom/prometheus:latest
    container_name: redditharbor-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
    networks:
      - redditharbor-network
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    container_name: redditharbor-grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards
    depends_on:
      - prometheus
    networks:
      - redditharbor-network
    restart: unless-stopped

  # Elasticsearch for Log Storage
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.8.0
    container_name: redditharbor-elasticsearch
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms1g -Xmx1g
      - xpack.security.enabled=false
      - xpack.security.enrollment.enabled=false
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
      - ./elasticsearch/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
    networks:
      - redditharbor-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Kibana for Log Visualization
  kibana:
    image: docker.elastic.co/kibana/kibana:8.8.0
    container_name: redditharbor-kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    volumes:
      - ./kibana/kibana.yml:/usr/share/kibana/config/kibana.yml
    depends_on:
      - elasticsearch
    networks:
      - redditharbor-network
    restart: unless-stopped

  # Logstash for Log Processing
  logstash:
    image: docker.elastic.co/logstash/logstash:8.8.0
    container_name: redditharbor-logstash
    volumes:
      - ./logstash/logstash.conf:/usr/share/logstash/pipeline/logstash.conf
      - ./logs:/var/log/app
      - elasticsearch_data:/usr/share/elasticsearch/data
    depends_on:
      - elasticsearch
    networks:
      - redditharbor-network
    restart: unless-stopped

  # Jaeger for Distributed Tracing
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: redditharbor-jaeger
    ports:
      - "16686:16686"
      - "16687:16687"
      - "14268:14268"
      - "14250:14250"
    environment:
      - COLLECTOR_ZIPKIN_HOST_PORT=9411
    networks:
      - redditharbor-network
    restart: unless-stopped

  # Worker Processes
  worker:
    build: .
    container_name: redditharbor-worker
    command: python scripts/worker.py
    environment:
      - REDDIT_CLIENT_ID=${REDDIT_CLIENT_ID}
      - REDDIT_CLIENT_SECRET=${REDDIT_CLIENT_SECRET}
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_KEY=${SUPABASE_KEY}
      - REDIS_URL=${REDIS_URL}
      - WORKER_TYPE=background
      - DEEP_GRAPH_PROJECT_ID=${DEEP_GRAPH_PROJECT_ID}
      - DEEP_GRAPH_API_KEY=${DEEP_GRAPH_API_KEY}
    volumes:
      - ./logs:/app/logs
      - ./backups:/app/backups
    depends_on:
      - redis
      - postgres
    networks:
      - redditharbor-network
    restart: unless-stopped
    deploy:
      replicas: 2

  # Scheduler for Automated Tasks
  scheduler:
    build: .
    container_name: redditharbor-scheduler
    command: python scripts/scheduler.py
    environment:
      - REDDIT_CLIENT_ID=${REDDIT_CLIENT_ID}
      - REDDIT_CLIENT_SECRET=${REDDIT_CLIENT_SECRET}
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_KEY=${SUPABASE_KEY}
      - REDIS_URL=${REDIS_URL}
      - SCHEDULE_INTERVAL=3600
      - DEEP_GRAPH_PROJECT_ID=${DEEP_GRAPH_PROJECT_ID}
      - DEEP_GRAPH_API_KEY=${DEEP_GRAPH_API_KEY}
    volumes:
      - ./logs:/app/logs
    depends_on:
      - redis
      - postgres
    networks:
      - redditharbor-network
    restart: unless-stopped

# Networks
networks:
  redditharbor-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

# Volumes
volumes:
  redis_data:
    driver: local
  postgres_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  elasticsearch_data:
    driver: local
      - redis_data:/data
    networks:
      - reddit-harbor-network
    restart: unless-stopped
    command: redis-server --appendonly yes

  # Supabase Database
  supabase-db:
    image: supabase/postgres:15.1.0.117
    container_name: reddit-harbor-db
    ports:
      - "54322:54322"
    environment:
      - POSTGRES_DB=postgres
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_HOST_AUTH_METHOD=trust
    volumes:
      - supabase_db_data:/var/lib/postgresql/data
    networks:
      - reddit-harbor-network
    restart: unless-stopped

  # Supabase Studio (Database Management UI)
  supabase-studio:
    image: supabase/studio:20231127-af483fe
    container_name: reddit-harbor-studio
    ports:
      - "54323:3000"
    environment:
      - SUPABASE_URL=http://supabase-kong:8000
      - SUPABASE_ANON_KEY=${SUPABASE_ANON_KEY}
      - SUPABASE_SERVICE_KEY=${SUPABASE_SERVICE_KEY}
    depends_on:
      - supabase-db
      - supabase-kong
    networks:
      - reddit-harbor-network
    restart: unless-stopped

  # Supabase Kong API Gateway
  supabase-kong:
    image: kong:3.4
    container_name: reddit-harbor-kong
    ports:
      - "54321:8000"
    environment:
      - KONG_DATABASE=off
      - KONG_DECLARATIVE_CONFIG=/kong/declarative/kong.yml
      - KONG_PROXY_ACCESS_LOG=/dev/stdout
      - KONG_ADMIN_ACCESS_LOG=/dev/stdout
      - KONG_PROXY_ERROR_LOG=/dev/stderr
      - KONG_ADMIN_ERROR_LOG=/dev/stderr
      - KONG_ADMIN_LISTEN=0.0.0.0:8001
    volumes:
      - ./supabase/kong.yml:/kong/declarative/kong.yml:ro
    depends_on:
      - supabase-db
    networks:
      - reddit-harbor-network
    restart: unless-stopped

  # Supabase Functions (Serverless Functions)
  supabase-functions:
    image: supabase/edge-runtime:v1.31.4
    container_name: reddit-harbor-functions
    ports:
      - "54324:9000"
    environment:
      - SUPABASE_URL=http://supabase-kong:8000
      - SUPABASE_ANON_KEY=${SUPABASE_ANON_KEY}
      - SUPABASE_SERVICE_ROLE_KEY=${SUPABASE_SERVICE_ROLE_KEY}
      - SUPABASE_DB_URL=postgresql://postgres:postgres@supabase-db:5432/postgres
    volumes:
      - ./supabase/functions:/home/deno/functions:ro
    depends_on:
      - supabase-db
      - supabase-kong
    networks:
      - reddit-harbor-network
    restart: unless-stopped

  # Supabase Auth
  supabase-auth:
    image: supabase/gotrue:v2.134.0
    container_name: reddit-harbor-auth
    ports:
      - "54325:9999"
    environment:
      - GOTRUE_API_HOST=0.0.0.0
      - GOTRUE_API_PORT=9999
      - API_EXTERNAL_URL=http://supabase-kong:8000
      - GOTRUE_DB_DRIVER=postgres
      - GOTRUE_DB_DATABASE_URL=postgresql://postgres:postgres@supabase-db:5432/postgres
      - GOTRUE_SITE_URL=http://localhost:3000
      - GOTRUE_URI_ALLOW_LIST=http://localhost:3000,http://localhost:8000
      - GOTRUE_DISABLE_SIGNUP=false
      - GOTRUE_JWT_SECRET=${SUPABASE_JWT_SECRET}
      - GOTRUE_JWT_EXP=3600
      - GOTRUE_JWT_DEFAULT_GROUP_NAME=authenticated
    depends_on:
      - supabase-db
    networks:
      - reddit-harbor-network
    restart: unless-stopped

  # Supabase REST API
  supabase-rest:
    image: postgrest/postgrest:v12.0.1
    container_name: reddit-harbor-rest
    ports:
      - "54326:3000"
    environment:
      - PGRST_DB_URI=postgresql://postgres:postgres@supabase-db:5432/postgres
      - PGRST_DB_SCHEMAS=public,storage,graphql_public
      - PGRST_DB_ANON_ROLE=anon
      - PGRST_JWT_SECRET=${SUPABASE_JWT_SECRET}
    depends_on:
      - supabase-db
    networks:
      - reddit-harbor-network
    restart: unless-stopped

  # Supabase Storage
  supabase-storage:
    image: supabase/storage-api:v0.44.0
    container_name: reddit-harbor-storage
    ports:
      - "54327:5000"
    environment:
      - ANON_KEY=${SUPABASE_ANON_KEY}
      - SERVICE_KEY=${SUPABASE_SERVICE_KEY}
      - POSTGREST_URL=http://supabase-rest:3000
      - DATABASE_URL=postgresql://postgres:postgres@supabase-db:5432/postgres
      - FILE_SIZE_LIMIT=52428800
      - STORAGE_BACKEND=file
      - FILE_STORAGE_BACKEND_PATH=/var/lib/storage
      - TENANT_ID=stub
      - REGION=stub
      - GLOBAL_S3_BUCKET=stub
    volumes:
      - supabase_storage_data:/var/lib/storage
    depends_on:
      - supabase-db
      - supabase-rest
    networks:
      - reddit-harbor-network
    restart: unless-stopped

  # Next.js Frontend (Development)
  # To enable, uncomment and create the frontend directory
  # frontend:
  #   build:
  #     context: ./frontend
  #     dockerfile: Dockerfile
  #   container_name: reddit-harbor-frontend
  #   ports:
  #     - "3000:3000"
  #   environment:
  #     - NEXT_PUBLIC_API_URL=http://localhost:8000
  #     - NEXT_PUBLIC_SUPABASE_URL=http://localhost:54321
  #     - NEXT_PUBLIC_SUPABASE_ANON_KEY=${SUPABASE_ANON_KEY}
  #   depends_on:
  #     - api
  #     - supabase-kong
  #   volumes:
  #     - ./frontend:/app
  #     - /app/node_modules
  #   networks:
  #     - reddit-harbor-network
  #   restart: unless-stopped

  # Nginx Reverse Proxy (Optional)
  # nginx:
  #   image: nginx:alpine
  #   container_name: reddit-harbor-nginx
  #   ports:
  #     - "80:80"
  #     - "443:443"
  #   volumes:
  #     - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
  #     - ./nginx/ssl:/etc/nginx/ssl:ro
  #   depends_on:
  #     - api
  #     - supabase-kong
  #   networks:
  #     - reddit-harbor-network
  #   restart: unless-stopped

# Networks
networks:
  reddit-harbor-network:
    driver: bridge

# Volumes
volumes:
  api_uploads:
    driver: local
  api_logs:
    driver: local
  redis_data:
    driver: local
  supabase_db_data:
    driver: local
  supabase_storage_data:
    driver: local