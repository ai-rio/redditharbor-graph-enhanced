# Migration: Add Simplicity Score and Opportunity Assessment Score

**File:** `20251114232013_add_simplicity_score_and_assessment.sql`
**Date:** 2025-11-14
**Risk Level:** LOW
**Estimated Duration:** ~30 seconds

## Purpose

This migration completes the RedditHarbor opportunity assessment methodology by adding the missing 6th scoring dimension (`simplicity_score`) and creating a consolidated `opportunity_assessment_score` that combines all 6 dimensions with their proper weights.

## Methodology Alignment

The opportunity assessment methodology requires **6 dimensions** with specific weights:

| # | Dimension | Weight | Status Before | Status After |
|---|-----------|--------|---------------|--------------|
| 1 | `market_demand` | 20% | ✅ EXISTS | ✅ EXISTS |
| 2 | `pain_intensity` | 25% | ✅ EXISTS | ✅ EXISTS |
| 3 | `monetization_potential` | 20% | ✅ EXISTS | ✅ EXISTS |
| 4 | `market_gap` | 10% | ✅ EXISTS | ✅ EXISTS |
| 5 | `technical_feasibility` | 5% | ✅ EXISTS | ✅ EXISTS |
| 6 | `simplicity_score` | 20% | ❌ MISSING | ✅ ADDED |

**Total Weights:** 20% + 25% + 20% + 10% + 5% + 20% = **100%** ✓

## Changes

### 1. Add `simplicity_score` Column
- **Type:** `NUMERIC(5,2)`
- **Range:** 0-100
- **Constraint:** `CHECK (simplicity_score >= 0 AND simplicity_score <= 100)`
- **Nullable:** YES
- **Computed:** NO

**Scoring Logic:**
```sql
CASE function_count
  WHEN 1 THEN 100.0  -- Single-purpose, ultra-simple
  WHEN 2 THEN 85.0   -- Focused, but not single-purpose
  WHEN 3 THEN 70.0   -- Moderate complexity
  WHEN ≥4 THEN 0.0   -- High complexity, disqualified
END
```

### 2. Add `opportunity_assessment_score` Computed Column
- **Type:** `NUMERIC(5,2) GENERATED ALWAYS AS (...) STORED`
- **Range:** 0-100
- **Nullable:** YES
- **Computed:** YES

**Formula:**
```sql
market_demand * 0.20 +
pain_intensity * 0.25 +
monetization_potential * 0.20 +
market_gap * 0.10 +
technical_feasibility * 0.05 +
simplicity_score * 0.20
```

### 3. Backfill Existing Records
- Uses `core_functions` if available (newer records)
- Falls back to `function_count` (older records)
- Sets `simplicity_score = 0.0` for NULL values
- Updates all existing records automatically

### 4. Create Index
- **Index:** `idx_workflow_results_opportunity_assessment_score`
- **Order:** DESC (for efficient sorting of top opportunities)

## Migration Steps

The migration performs the following steps in order:

1. **Drop existing `simplicity_score`** (if exists with wrong type)
2. **Add `simplicity_score`** with correct type and constraints
3. **Backfill `simplicity_score`** from existing `function_count`/`core_functions` data
4. **Add `opportunity_assessment_score`** as computed column
5. **Create index** for efficient querying
6. **Log statistics** to verify successful migration

## How to Apply

### Option 1: Using Supabase CLI (Recommended)
```bash
cd /home/carlos/projects/redditharbor
supabase db push
```

### Option 2: Manual Application
```bash
psql postgresql://postgres:postgres@127.0.0.1:54322/postgres \
  -f supabase/migrations/20251114232013_add_simplicity_score_and_assessment.sql
```

## Verification

After applying the migration, run the verification script:

```bash
psql postgresql://postgres:postgres@127.0.0.1:54322/postgres \
  -f supabase/migrations/VERIFY_20251114232013_add_simplicity_score_and_assessment.sql
```

### Key Verification Checks

1. **Schema:** Both columns exist with correct types
2. **Constraints:** `simplicity_score` has 0-100 range check
3. **Index:** Assessment score index exists
4. **Data:** Simplicity scores match function counts
5. **Formula:** Assessment scores calculated correctly
6. **Range:** All scores within 0-100 bounds

### Quick Manual Checks

```sql
-- Check column types
SELECT column_name, data_type, numeric_precision, numeric_scale
FROM information_schema.columns
WHERE table_name = 'workflow_results'
  AND column_name IN ('simplicity_score', 'opportunity_assessment_score');

-- Check backfill completeness
SELECT
  COUNT(*) as total,
  COUNT(simplicity_score) as with_simplicity,
  COUNT(opportunity_assessment_score) as with_assessment
FROM workflow_results;

-- View top opportunities
SELECT app_name, opportunity_assessment_score, simplicity_score
FROM workflow_results
ORDER BY opportunity_assessment_score DESC
LIMIT 10;
```

## Rollback

If you need to rollback this migration:

```bash
psql postgresql://postgres:postgres@127.0.0.1:54322/postgres \
  -f supabase/migrations/ROLLBACK_20251114232013_add_simplicity_score_and_assessment.sql
```

**WARNING:** Rollback will permanently delete the `simplicity_score` and `opportunity_assessment_score` columns and their data. Make sure to backup before rolling back.

## Risks and Considerations

### LOW RISK FACTORS
- ✅ Non-breaking change (adds new columns only)
- ✅ Does not modify existing columns
- ✅ Backward compatible with existing queries
- ✅ Computed column automatically updates
- ✅ Includes comprehensive validation

### IMPORTANT NOTES
1. **Existing `simplicity_score` Column:** The schema dump shows an existing `simplicity_score` column with type `DOUBLE PRECISION`. This migration drops and recreates it as `NUMERIC(5,2)` for consistency with other dimensions.

2. **NULL Handling:** The computed column uses `COALESCE()` to treat NULL values as 0, ensuring the assessment score is always calculable.

3. **Function Count Sources:** Newer records use `core_functions` (BIGINT), while older records use `function_count` (INTEGER). The backfill logic handles both.

4. **Performance Impact:** Minimal - the stored computed column is updated automatically on INSERT/UPDATE, and the index enables efficient sorting.

5. **Data Loss:** If you rollback, you'll lose the `simplicity_score` and `opportunity_assessment_score` data. The rollback script restores the old `simplicity_score` column structure but NOT the data.

## Impact on Existing Code

### Queries That Will Continue Working
- All existing SELECT queries (new columns are optional)
- All existing INSERT queries (new columns have defaults/computed values)
- All existing UPDATE queries (computed column updates automatically)

### Recommended Updates
After migration, update your code to:
1. Use `opportunity_assessment_score` instead of `final_score` for ranking
2. Populate `simplicity_score` when inserting new records
3. Update dashboards to show all 6 dimensions

### Example: Insert New Record
```python
# Old way (still works)
insert_data = {
    'opportunity_id': 'opp_123',
    'app_name': 'TaskMaster',
    'function_count': 2,
    'market_demand': 85.0,
    'pain_intensity': 90.0,
    # ... other fields
}

# New way (recommended)
insert_data = {
    'opportunity_id': 'opp_123',
    'app_name': 'TaskMaster',
    'function_count': 2,
    'simplicity_score': 85.0,  # NEW: Add this
    'market_demand': 85.0,
    'pain_intensity': 90.0,
    # ... other fields
    # opportunity_assessment_score will be computed automatically
}
```

## Files

- **Migration:** `/home/carlos/projects/redditharbor/supabase/migrations/20251114232013_add_simplicity_score_and_assessment.sql`
- **Verification:** `/home/carlos/projects/redditharbor/supabase/migrations/VERIFY_20251114232013_add_simplicity_score_and_assessment.sql`
- **Rollback:** `/home/carlos/projects/redditharbor/supabase/migrations/ROLLBACK_20251114232013_add_simplicity_score_and_assessment.sql`
- **Documentation:** `/home/carlos/projects/redditharbor/supabase/migrations/README_20251114232013.md` (this file)

## Next Steps

1. **Review** this documentation and the migration SQL
2. **Backup** your database (if in production)
3. **Apply** the migration: `supabase db push`
4. **Verify** using the verification script
5. **Update** application code to use `opportunity_assessment_score`
6. **Update** dashboards and reports to show all 6 dimensions
